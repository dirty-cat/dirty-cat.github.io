{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Deduplicating misspelled categories with deduplicate\n\nA common step in data analyses is grouping or analyzing data conditional on a\ncategorical variable. In real world datasets, there often will be slight\nmisspellings in the category names: This happens when, for example, data input\n*should* use a drop down menu, but users are forced to input the category name\nby hand. Misspellings happen and analyzing the resulting data using a simple\n`GROUP BY` is not possible anymore.\n\nThis problem is however the perfect use case of *unsupervised learning*, a\ncategory of various statical methods that find structure in data without\nproviding explicit labels/categories of the data a-priori. Specifically\nclustering of the distance between strings can be used to find clusters\nof strings that are similar to each other (e.g. differ only by a misspelling)\nand hence gives us an easy tool to flag potentially misspelled category names\nin an unsupervised manner.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## An example\n\nImagine the following example:\nAs a data scientist, our job is to analyze the data from a hospital ward.\nWe notice that most of the cases involve the prescription of one of three different medications:\n \"Contrivan\", \"Genericon\", or \"Zipholan\".\nHowever, data entry is manual and - either because the prescribing doctor's handwriting\nwas hard to decipher, or due to mistakes during data input - there are multiple\nspelling mistakes for these three medications.\n\nLet's generate some example data that demonstrate this.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dirty_cat.datasets import make_deduplication_data\n\n# set seed for reproducibility\nnp.random.seed(123)\n\n# our three medication names\nmedications = [\"Contrivan\", \"Genericon\", \"Zipholan\"]\nentries_per_medications = [500, 100, 1500]\n\n# 5% probability of a typo per letter\nprob_mistake_per_letter = 0.05\n\ndata = make_deduplication_data(\n    medications, entries_per_medications, prob_mistake_per_letter\n)\n# we extract the unique medication names in the data & how often they appear\nunique_examples, counts = np.unique(data, return_counts=True)\n# and build a series out of them\nex_series = pd.Series(counts, index=unique_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ex_series.plot.barh(figsize=(10, 15))\nplt.xlabel(\"Medication name\")\nplt.ylabel(\"Counts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now see clearly the structure of the data: The three original medications\nare the most common ones, however there are many spelling mistakes and hence\nmany slight variations of the names of the original medications.\n\nThe idea is to use the fact that the string-distance of each misspelled medication\nname will be closest to either the correctly or incorrectly spelled orginal\nmedication name - and therefore form clusters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dirty_cat import deduplicate\nfrom dirty_cat._deduplicate import compute_ngram_distance\nfrom scipy.spatial.distance import squareform\n\nngram_distances = compute_ngram_distance(unique_examples)\nsquare_distances = squareform(ngram_distances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We can visualize the pair-wise distance between all medication names\n\nBelow we use a heatmap to visualize the pairwise-distance between medication names.\nA darker color means that two medication names are closer together (i.e. more similar),\na lighter color means a larger distance. We can see that we are dealing with three\nclusters - the original medication names and their misspellings that cluster around them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n\nfig, axes = plt.subplots(1, 1, figsize=(12, 12))\nsns.heatmap(\n    square_distances, yticklabels=ex_series.index, xticklabels=ex_series.index, ax=axes\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering to suggest corrections of misspelled names\n\nThe number of clusters will need some adjustment depending on the data you have.\nIf no fixed number of clusters is given, `deduplicate` tries to set it automatically\nvia the [silhouette score](https://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "deduplicated_data = deduplicate(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize the distribution of categories in the deduplicated data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "deduplicated_unique_examples, deduplicated_counts = np.unique(\n    deduplicated_data, return_counts=True\n)\ndeduplicated_series = pd.Series(deduplicated_counts, index=deduplicated_unique_examples)\n\ndeduplicated_series.plot.barh(figsize=(10, 15))\nplt.xlabel(\"Medication name\")\nplt.ylabel(\"Counts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we can correct all spelling mistakes by using the ideal number\nof clusters as determined by the silhouette score.\n\nHowever, often the translation/deduplication won't be perfect and will require some tweaks.\nIn this case, we can construct and update a translation table based on the data\nreturned by `deduplicate`.\nIt consists of the (potentially) misspelled category names as indices and the\n(potentially) correct categories as values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create a table that maps original -> corrected categories\ntranslation_table = pd.Series(deduplicated_data, index=data)\n\n# remove duplicates in the original data\ntranslation_table = translation_table[~translation_table.index.duplicated(keep=\"first\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the number of correct spellings will likely be much smaller than the\nnumber of original categories, we can print the estimated cluster and their\nmost common exemplars (the guessed correct spelling):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def print_corrections(spell_correct):\n    correct = np.unique(spell_correct.values)\n    for c in correct:\n        print(\n            f\"Guessed correct spelling: {c!r} for \"\n            f\"{spell_correct[spell_correct==c].index.values}\"\n        )\n\n\nprint_corrections(translation_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In case we want to adapt the translation table post-hoc we can easily do so:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "translation_table[\"Gszericon\"] = \"Completely new category\"\nnew_deduplicated_data = translation_table[data]\nassert (new_deduplicated_data == \"Completely new category\").sum() > 0"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}