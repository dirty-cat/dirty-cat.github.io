
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

<meta property="og:title" content="dirty_cat.SuperVectorizer" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://dirty-cat.github.io/stable/generated/dirty_cat.SuperVectorizer.html" />
  
<meta property="og:site_name" content="dirty_cat" />
  
<meta property="og:description" content="Usage examples at the bottom of this page. Examples using dirty_cat.SuperVectorizer: Dirty categories: machine learning with non normalized strings Dirty categories: machine learning with non norma..." />
  
<meta property="og:image" content="https://dirty-cat.github.io/stable/_images/sphx_glr_01_dirty_categories_thumb.png" />
  
<meta property="og:image:alt" content="Dirty categories: machine learning with non normalized strings" />
  
    <title>dirty_cat.SuperVectorizer &#8212; &amp;mdash; Dirty cat</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scrolltoc.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="dirty_cat.GapEncoder" href="dirty_cat.GapEncoder.html" />
    <link rel="prev" title="Scalability considerations for similarity encoding" href="../auto_examples/06_dimension_reduction_and_performance.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><!--
    Inherited from the original Alabaster theme:
    https://github.com/bitprophet/alabaster/blob/master/alabaster/about.html
    Only the "Version" number is added.
-->

<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/dirty_cat.svg" alt="Logo"/>
    
    <h1 class="logo logo-name">dirty_cat</h1>
    
  </a>
  <h4>Version 0.4.dev0</h4>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=dirty-cat&repo=dirty_cat&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<ul>
    <li class="toctree-l1"><a href="../index.html#using-dirty-cat">Usage</a></li>
    <li class="toctree-l1"><a href="../index.html#api-documentation">API</a></li>
    <li class="toctree-l1"><a href="../index.html#about">About</a></li>
</ul>
  <h3 class="this-page"><a href="../index.html">This page</a></h3>
  <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dirty_cat</span></code>.SuperVectorizer</a><ul>
<li><a class="reference internal" href="#examples-using-dirty-cat-supervectorizer">Examples using <code class="docutils literal notranslate"><span class="pre">dirty_cat.SuperVectorizer</span></code></a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../auto_examples/06_dimension_reduction_and_performance.html" title="previous chapter">Scalability considerations for similarity encoding</a></li>
      <li>Next: <a href="dirty_cat.GapEncoder.html" title="next chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dirty_cat</span></code>.GapEncoder</a></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="dirty-cat-supervectorizer">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">dirty_cat</span></code>.SuperVectorizer<a class="headerlink" href="#dirty-cat-supervectorizer" title="Permalink to this heading">¶</a></h1>
<p class="side-comment">Usage examples at the bottom of this page.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dirty_cat.</span></span><span class="sig-name descname"><span class="pre">SuperVectorizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cardinality_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_card_cat_transformer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high_card_cat_transformer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numerical_transformer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datetime_transformer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_cast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">impute_missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remainder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'passthrough'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformer_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dirty_cat/_super_vectorizer.html#SuperVectorizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.SuperVectorizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Easily transforms a heterogeneous data table (such as a dataframe) to
a numerical array for machine learning. For this it transforms each
column depending on its data type.
It provides a simplified interface for the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="(in scikit-learn v1.1)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.compose.ColumnTransformer</span></code></a> ;
more documentation of attributes and functions are available in its doc.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.2.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cardinality_threshold</strong><span class="classifier">int, default=40</span></dt><dd><p>Two lists of features will be created depending on this value: strictly
under this value, the low cardinality categorical features, and above or
equal, the high cardinality categorical features.
Different transformers will be applied to these two groups,
defined by the parameters <cite>low_card_cat_transformer</cite> and
<cite>high_card_cat_transformer</cite> respectively.
Note: currently, missing values are counted as a single unique value
(so they count in the cardinality).</p>
</dd>
<dt><strong>low_card_cat_transformer</strong><span class="classifier">typing.Optional[typing.Union[sklearn.base.TransformerMixin, typing.Literal[“drop”, “remainder”, “passthrough”]]], default=None  # noqa</span></dt><dd><p>Transformer used on categorical/string features with low cardinality
(threshold is defined by <cite>cardinality_threshold</cite>).
Can either be a transformer object instance (e.g. <cite>OneHotEncoder(drop=”if_binary”)</cite>),
a <cite>Pipeline</cite> containing the preprocessing steps,
‘drop’ for dropping the columns,
‘remainder’ for applying <cite>remainder</cite>,
‘passthrough’ to return the unencoded columns,
or None to use the default transformer (<cite>OneHotEncoder()</cite>).
Features classified under this category are imputed based on the
strategy defined with <cite>impute_missing</cite>.</p>
</dd>
<dt><strong>high_card_cat_transformer</strong><span class="classifier">typing.Optional[typing.Union[sklearn.base.TransformerMixin, typing.Literal[“drop”, “remainder”, “passthrough”]]], default=None  # noqa</span></dt><dd><p>Transformer used on categorical/string features with high cardinality
(threshold is defined by <cite>cardinality_threshold</cite>).
Can either be a transformer object instance (e.g. <cite>GapEncoder()</cite>),
a <cite>Pipeline</cite> containing the preprocessing steps,
‘drop’ for dropping the columns,
‘remainder’ for applying <cite>remainder</cite>,
‘passthrough’ to return the unencoded columns,
or None to use the default transformer (<cite>GapEncoder(n_components=30)</cite>).
Features classified under this category are imputed based on the
strategy defined with <cite>impute_missing</cite>.</p>
</dd>
<dt><strong>numerical_transformer</strong><span class="classifier">typing.Optional[typing.Union[sklearn.base.TransformerMixin, typing.Literal[“drop”, “remainder”, “passthrough”]]], default=None  # noqa</span></dt><dd><p>Transformer used on numerical features.
Can either be a transformer object instance (e.g. <cite>StandardScaler()</cite>),
a <cite>Pipeline</cite> containing the preprocessing steps,
‘drop’ for dropping the columns,
‘remainder’ for applying <cite>remainder</cite>,
‘passthrough’ to return the unencoded columns,
or None to use the default transformer (here nothing, so ‘passthrough’).
Features classified under this category are not imputed at all
(regardless of <cite>impute_missing</cite>).</p>
</dd>
<dt><strong>datetime_transformer</strong><span class="classifier">typing.Optional[typing.Union[sklearn.base.TransformerMixin, typing.Literal[“drop”, “remainder”, “passthrough”]]], default=None</span></dt><dd><p>Transformer used on datetime features.
Can either be a transformer object instance (e.g. <cite>DatetimeEncoder()</cite>),
a <cite>Pipeline</cite> containing the preprocessing steps,
‘drop’ for dropping the columns,
‘remainder’ for applying <cite>remainder</cite>,
‘passthrough’ to return the unencoded columns,
or None to use the default transformer (<cite>DatetimeEncoder()</cite>).
Features classified under this category are not imputed at all
(regardless of <cite>impute_missing</cite>).</p>
</dd>
<dt><strong>auto_cast</strong><span class="classifier">bool, default=True</span></dt><dd><p>If set to <cite>True</cite>, will try to convert each column to the best possible
data type (dtype).</p>
</dd>
<dt><strong>impute_missing</strong><span class="classifier">str, default=’auto’</span></dt><dd><p>When to impute missing values in categorical (textual) columns.
‘auto’ will impute missing values if it is considered appropriate
(we are using an encoder that does not support missing values and/or
specific versions of pandas, numpy and scikit-learn).
‘force’ will impute missing values in all categorical columns.
‘skip’ will not impute at all.
When imputed, missing values are replaced by the string ‘missing’.
As imputation logic for numerical features can be quite intricate,
it is left to the user to manage.
See also attribute <cite>imputed_columns_</cite>.</p>
</dd>
<dt><strong>remainder</strong><span class="classifier">typing.Union[typing.Literal[“drop”, “passthrough”], sklearn.base.TransformerMixin], default=’drop’  # noqa</span></dt><dd><p>By default, only the specified columns in <cite>transformers</cite> are
transformed and combined in the output, and the non-specified
columns are dropped. (default <code class="docutils literal notranslate"><span class="pre">'drop'</span></code>).
By specifying <code class="docutils literal notranslate"><span class="pre">remainder='passthrough'</span></code>, all remaining columns that
were not specified in <cite>transformers</cite> will be automatically passed
through. This subset of columns is concatenated with the output of
the transformers.
By setting <code class="docutils literal notranslate"><span class="pre">remainder</span></code> to be an estimator, the remaining
non-specified columns will use the <code class="docutils literal notranslate"><span class="pre">remainder</span></code> estimator. The
estimator must support <a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-fit" title="(in scikit-learn v1.1)"><span class="xref std std-term">fit</span></a> and <a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-transform" title="(in scikit-learn v1.1)"><span class="xref std std-term">transform</span></a>.
Note that using this feature requires that the DataFrame columns
input at <a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-fit" title="(in scikit-learn v1.1)"><span class="xref std std-term">fit</span></a> and <a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-transform" title="(in scikit-learn v1.1)"><span class="xref std std-term">transform</span></a> have identical order.</p>
</dd>
<dt><strong>sparse_threshold: float, default=0.3</strong></dt><dd><p>If the output of the different transformers contains sparse matrices,
these will be stacked as a sparse matrix if the overall density is
lower than this value. Use sparse_threshold=0 to always return dense.
When the transformed output consists of all dense data, the stacked
result will be dense, and this keyword will be ignored.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">int, default=None</span></dt><dd><p>Number of jobs to run in parallel.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors.</p>
</dd>
<dt><strong>transformer_weights</strong><span class="classifier">dict, default=None</span></dt><dd><p>Multiplicative weights for features per transformer. The output of the
transformer is multiplied by these weights. Keys are transformer names,
values the weights.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, default=False</span></dt><dd><p>If True, the time elapsed while fitting each transformer will be
printed as it is completed</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The column order of the input data is not guaranteed to be the same
as the output data (returned by <cite>transform</cite>).
This is a due to the way the ColumnTransformer works.
However, the output column order will always be the same for different
calls to <cite>transform</cite> on a same fitted SuperVectorizer instance.
For example, if input data has columns [‘name’, ‘job’, ‘year], then output
columns might be shuffled, e.g., [‘job’, ‘year’, ‘name’], but every call
to <cite>transform</cite> will return this order.</p>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>transformers_: typing.List[typing.Tuple[str, typing.Union[str, sklearn.base.TransformerMixin], typing.List[str]]]  # noqa</strong></dt><dd><p>The collection of fitted transformers as tuples of
(name, fitted_transformer, column). <cite>fitted_transformer</cite> can be an
estimator, ‘drop’, or ‘passthrough’. In case there were no columns
selected, this will be an unfitted transformer.
If there are remaining columns, the final element is a tuple of the
form:
(‘remainder’, transformer, remaining_columns) corresponding to the
<code class="docutils literal notranslate"><span class="pre">remainder</span></code> parameter. If there are remaining columns, then
<code class="docutils literal notranslate"><span class="pre">len(transformers_)==len(transformers)+1</span></code>, otherwise
<code class="docutils literal notranslate"><span class="pre">len(transformers_)==len(transformers)</span></code>.</p>
</dd>
<dt><strong>columns_: pandas.Index</strong></dt><dd><p>The fitted array’s columns. They are applied to the data passed
to the <cite>transform</cite> method.</p>
</dd>
<dt><strong>types_: typing.Dict[str, type]</strong></dt><dd><p>A mapping of inferred types per column.
Key is the column name, value is the inferred dtype.
Exists only if <cite>auto_cast=True</cite>.</p>
</dd>
<dt><strong>imputed_columns_: typing.List[str]</strong></dt><dd><p>The list of columns in which we imputed the missing values.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.SuperVectorizer.fit" title="dirty_cat.SuperVectorizer.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X[, y])</p></td>
<td><p>Fit all transformers using X.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dirty_cat.SuperVectorizer.fit_transform" title="dirty_cat.SuperVectorizer.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(X[, y])</p></td>
<td><p>Fit all transformers, transform the data, and concatenate the results.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.SuperVectorizer.get_feature_names" title="dirty_cat.SuperVectorizer.get_feature_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names</span></code></a>([input_features])</p></td>
<td><p>Ensures compatibility with sklearn &lt; 1.0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dirty_cat.SuperVectorizer.get_feature_names_out" title="dirty_cat.SuperVectorizer.get_feature_names_out"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names_out</span></code></a>([input_features])</p></td>
<td><p>Returns clean feature names with format &quot;&lt;column_name&gt;_&lt;value&gt;&quot; if encoded by OneHotEncoder or alike, e.g.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.SuperVectorizer.get_params" title="dirty_cat.SuperVectorizer.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dirty_cat.SuperVectorizer.set_params" title="dirty_cat.SuperVectorizer.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**kwargs)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.SuperVectorizer.transform" title="dirty_cat.SuperVectorizer.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(X)</p></td>
<td><p>Transform X by applying fitted transformers on each column, and concatenate the results.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dirty_cat.SuperVectorizer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit all transformers using X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, dataframe} of shape (n_samples, n_features)</span></dt><dd><p>Input data, of which specified subsets are used to fit the
transformers.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,…), default=None</span></dt><dd><p>Targets for supervised learning.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">ColumnTransformer</span></dt><dd><p>This estimator.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dirty_cat/_super_vectorizer.html#SuperVectorizer.fit_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.SuperVectorizer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit all transformers, transform the data, and concatenate the results.
In practice, it (1) converts features to their best possible types
if <cite>auto_cast=True</cite>, (2) classify columns based on their data type,
(3) replaces “false missing” (see function <cite>_replace_false_missing</cite>),
and imputes categorical columns depending on <cite>impute_missing</cite>, and
finally, transforms X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, dataframe} of shape (n_samples, n_features)</span></dt><dd><p>Input data, of which specified subsets are used to fit the
transformers.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Targets for supervised learning.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>{array-like, sparse matrix} of shape (n_samples, sum_n_components)</dt><dd><p>hstack of results of transformers. sum_n_components is the
sum of n_components (output dimension) over transformers. If
any result is a sparse matrix, everything will be converted to
sparse matrices.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer.get_feature_names">
<span class="sig-name descname"><span class="pre">get_feature_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dirty_cat/_super_vectorizer.html#SuperVectorizer.get_feature_names"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.SuperVectorizer.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Ensures compatibility with sklearn &lt; 1.0.
Use <cite>get_feature_names_out</cite> instead.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer.get_feature_names_out">
<span class="sig-name descname"><span class="pre">get_feature_names_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dirty_cat/_super_vectorizer.html#SuperVectorizer.get_feature_names_out"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.SuperVectorizer.get_feature_names_out" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns clean feature names with format
“&lt;column_name&gt;_&lt;value&gt;” if encoded by OneHotEncoder or alike,
e.g. “job_title_Police officer”, or “&lt;column_name&gt;” otherwise.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>typing.List[str]</dt><dd><p>Feature names.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dirty_cat.SuperVectorizer.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<p>Returns the parameters given in the constructor as well as the
estimators contained within the <cite>transformers</cite> of the
<cite>ColumnTransformer</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer.named_transformers_">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">named_transformers_</span></span><a class="headerlink" href="#dirty_cat.SuperVectorizer.named_transformers_" title="Permalink to this definition">¶</a></dt>
<dd><p>Access the fitted transformer by name.</p>
<p>Read-only attribute to access any transformer by given name.
Keys are transformer names and values are the fitted transformer
objects.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dirty_cat.SuperVectorizer.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>Valid parameter keys can be listed with <code class="docutils literal notranslate"><span class="pre">get_params()</span></code>. Note that you
can directly set the parameters of the estimators contained in
<cite>transformers</cite> of <cite>ColumnTransformer</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**kwargs</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">ColumnTransformer</span></dt><dd><p>This estimator.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.SuperVectorizer.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dirty_cat/_super_vectorizer.html#SuperVectorizer.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.SuperVectorizer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X by applying fitted transformers on each column,
and concatenate the results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, dataframe} of shape (n_samples, n_features)</span></dt><dd><p>The data to be transformed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>{array-like, sparse matrix} of shape (n_samples, sum_n_components)</dt><dd><p>hstack of results of transformers. sum_n_components is the
sum of n_components (output dimension) over transformers. If
any result is a sparse matrix, everything will be converted to
sparse matrices.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-dirty-cat-supervectorizer">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">dirty_cat.SuperVectorizer</span></code><a class="headerlink" href="#examples-using-dirty-cat-supervectorizer" title="Permalink to this heading">¶</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Including strings that represent categories often calls for much data preparation. In particula..."><img alt="Dirty categories: machine learning with non normalized strings" src="../_images/sphx_glr_01_dirty_categories_thumb.png" />
<p><a class="reference internal" href="../auto_examples/01_dirty_categories.html#sphx-glr-auto-examples-01-dirty-categories-py"><span class="std std-ref">Dirty categories: machine learning with non normalized strings</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dirty categories: machine learning with non normalized strings</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We illustrate here how to handle datetime features with the DatetimeEncoder."><img alt="Handling datetime features with the DatetimeEncoder" src="../_images/sphx_glr_04_datetime_encoder_thumb.png" />
<p><a class="reference internal" href="../auto_examples/04_datetime_encoder.html#sphx-glr-auto-examples-04-datetime-encoder-py"><span class="std std-ref">Handling datetime features with the DatetimeEncoder</span></a></p>
  <div class="sphx-glr-thumbnail-title">Handling datetime features with the DatetimeEncoder</div>
</div></div><div class="clearer"></div></section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2018-2021, dirty_cat developers.
      
      |
      <a href="../_sources/generated/dirty_cat.SuperVectorizer.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>