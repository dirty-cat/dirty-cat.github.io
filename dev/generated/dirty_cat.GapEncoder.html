
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<meta property="og:title" content="dirty_cat.GapEncoder" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://dirty-cat.github.io/stable/generated/dirty_cat.GapEncoder.html" />
<meta property="og:site_name" content="dirty_cat" />
<meta property="og:description" content="Usage examples at the bottom of this page. Examples using dirty_cat.GapEncoder: Dirty categories: machine learning with non normalized strings Dirty categories: machine learning with non normalized..." />
<meta property="og:image" content="https://dirty-cat.github.io/stable/_images/sphx_glr_01_dirty_categories_thumb.png" />
<meta property="og:image:alt" content="Dirty categories: machine learning with non normalized strings" />
<meta name="description" content="Usage examples at the bottom of this page. Examples using dirty_cat.GapEncoder: Dirty categories: machine learning with non normalized strings Dirty categories: machine learning with non normalized..." />

    <title>dirty_cat.GapEncoder &#8212; dirty_cat</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scrolltoc.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="dirty_cat.MinHashEncoder" href="dirty_cat.MinHashEncoder.html" />
    <link rel="prev" title="dirty_cat.SuperVectorizer" href="dirty_cat.SuperVectorizer.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><!--
    Inherited from the original Alabaster theme:
    https://github.com/bitprophet/alabaster/blob/master/alabaster/about.html
    Only the "Version" number is added.
-->


<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/dirty_cat.svg" alt="Logo"/>
    
    <h1 class="logo logo-name">dirty_cat</h1>
    
  </a>
  <div class="version-switcher">
    <h4>Version 0.4.0b1</h4>
    <details>
	<summary>Other versions</summary>
	<ul>
	    <li><a href="https://dirty-cat.github.io/stable">Stable</a></li>
	    <li><a href="https://dirty-cat.github.io/dev">Dev</a></li>
	</ul>
    </details>
  </div>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=dirty-cat&repo=dirty_cat&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<ul>
    <li class="toctree-l1"><a href="../index.html#usage-examples">Usage</a></li>
    <li class="toctree-l1"><a href="../index.html#api-documentation">API</a></li>
    <li class="toctree-l1"><a href="../index.html#about">About</a></li>
</ul>
  <h3 class="this-page"><a href="../index.html">This page</a></h3>
  <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dirty_cat</span></code>.GapEncoder</a><ul>
<li><a class="reference internal" href="#examples-using-dirty-cat-gapencoder">Examples using <code class="docutils literal notranslate"><span class="pre">dirty_cat.GapEncoder</span></code></a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="dirty_cat.SuperVectorizer.html" title="previous chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dirty_cat</span></code>.SuperVectorizer</a></li>
      <li>Next: <a href="dirty_cat.MinHashEncoder.html" title="next chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dirty_cat</span></code>.MinHashEncoder</a></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="dirty-cat-gapencoder">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">dirty_cat</span></code>.GapEncoder<a class="headerlink" href="#dirty-cat-gapencoder" title="Permalink to this heading">¶</a></h1>
<p class="side-comment">Usage examples at the bottom of this page.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dirty_cat.</span></span><span class="sig-name descname"><span class="pre">GapEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma_shape_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma_scale_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale_rho</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hashing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hashing_n_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'k-means++'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ngram_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(2,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analyzer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'char'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_words</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale_W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_e_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">handle_missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zero_impute'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/_gap_encoder.py#L546"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs latent topics with continuous encoding.</p>
<p>This encoder can be understood as a continuous encoding on a set of latent
categories estimated from the data. The latent categories are built by
capturing combinations of substrings that frequently co-occur.</p>
<p>The <a class="reference internal" href="#dirty_cat.GapEncoder" title="dirty_cat.GapEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GapEncoder</span></code></a> supports online learning on batches of
data for scalability through the <a class="reference internal" href="#dirty_cat.GapEncoder.partial_fit" title="dirty_cat.GapEncoder.partial_fit"><code class="xref py py-func docutils literal notranslate"><span class="pre">partial_fit()</span></code></a>
method.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>n_components</strong><span class="classifier">int, optional, default=10</span></dt><dd><p>Number of latent categories used to model string data.</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, optional, default=128</span></dt><dd><p>Number of samples per batch.</p>
</dd>
<dt><strong>gamma_shape_prior</strong><span class="classifier">float, optional, default=1.1</span></dt><dd><p>Shape parameter for the Gamma prior distribution.</p>
</dd>
<dt><strong>gamma_scale_prior</strong><span class="classifier">float, optional, default=1.0</span></dt><dd><p>Scale parameter for the Gamma prior distribution.</p>
</dd>
<dt><strong>rho</strong><span class="classifier">float, optional, default=0.95</span></dt><dd><p>Weight parameter for the update of the <em>W</em> matrix.</p>
</dd>
<dt><strong>rescale_rho</strong><span class="classifier">bool, optional, default=False</span></dt><dd><p>If true, use <code class="docutils literal notranslate"><span class="pre">rho</span> <span class="pre">**</span> <span class="pre">(batch_size</span> <span class="pre">/</span> <span class="pre">len(X))</span></code> instead of rho to obtain an
update rate per iteration that is independent of the batch size.</p>
</dd>
<dt><strong>hashing</strong><span class="classifier">bool, optional, default=False</span></dt><dd><p>If true, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">HashingVectorizer</span></code></a>
is used instead of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">CountVectorizer</span></code></a>.
It has the advantage of being very low memory, scalable to large
datasets as there is no need to store a vocabulary dictionary in
memory.</p>
</dd>
<dt><strong>hashing_n_features</strong><span class="classifier">int, optional, default=2**12</span></dt><dd><p>Number of features for the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">HashingVectorizer</span></code></a>.
Only relevant if <cite>hashing=True</cite>.</p>
</dd>
<dt><strong>init</strong><span class="classifier">{“k-means++”, “random”, “k-means”}, optional, default=’k-means++’</span></dt><dd><p>Initialization method of the W matrix.
If <cite>init=’k-means++’</cite>, we use the init method of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a>.
If <cite>init=’random’</cite>, topics are initialized with a Gamma distribution.
If <cite>init=’k-means’</cite>, topics are initialized with a KMeans on the n-grams
counts. This usually makes convergence faster but is a bit slower.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, default=1e-4</span></dt><dd><p>Tolerance for the convergence of the matrix <em>W</em>.</p>
</dd>
<dt><strong>min_iter</strong><span class="classifier">int, optional, default=2</span></dt><dd><p>Minimum number of iterations on the input data.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, optional, default=5</span></dt><dd><p>Maximum number of iterations on the input data.</p>
</dd>
<dt><strong>ngram_range</strong><span class="classifier">int 2-tuple, optional, default=(2, 4)</span></dt><dd><p>The range of ngram length that will be used to build the
bag-of-n-grams representation of the input data.</p>
</dd>
<dt><strong>analyzer</strong><span class="classifier">{“word”, “char”, “char_wb”}, optional, default=’char’</span></dt><dd><p>Analyzer parameter for the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">HashingVectorizer</span></code></a>
/ <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">CountVectorizer</span></code></a>.
Describes whether the matrix <em>V</em> to factorize should be made of word counts
or character n-gram counts.
Option ‘char_wb’ creates character n-grams only from text inside word
boundaries; n-grams at the edges of words are padded with space.</p>
</dd>
<dt><strong>add_words</strong><span class="classifier">bool, optional, default=False</span></dt><dd><p>If true, add the words counts to the bag-of-n-grams representation
of the input data.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, <a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(in NumPy v1.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.random.RandomState</span></code></a> or None, optional, default=None</span></dt><dd><p>RNG seed for reproducible output across multiple function calls.</p>
</dd>
<dt><strong>rescale_W</strong><span class="classifier">bool, optional, default=True</span></dt><dd><p>If true, the weight matrix <em>W</em> is rescaled at each iteration
to have a l1 norm equal to 1 for each row.</p>
</dd>
<dt><strong>max_iter_e_step</strong><span class="classifier">int, default=20</span></dt><dd><p>Maximum number of iterations to adjust the activations h at each step.</p>
</dd>
<dt><strong>handle_missing</strong><span class="classifier">{“error”, “empty_impute”}, optional, default=’empty_impute’</span></dt><dd><p>Whether to raise an error or impute with empty string <code class="docutils literal notranslate"><span class="pre">''</span></code> if missing
values (NaN) are present during fit (default is to impute).
In the inverse transform, the missing category will be denoted as None.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<p>For a detailed description of the method, see
<a class="reference external" href="https://hal.inria.fr/hal-02171256v4">Encoding high-cardinality string categorical variables</a> by Cerda, Varoquaux (2019).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">GapEncoder</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s encode the following non-normalized data:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;paris, FR&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Paris&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;London, UK&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Paris, France&#39;</span><span class="p">],</span>
<span class="go">         [&#39;london&#39;], [&#39;London, England&#39;], [&#39;London&#39;], [&#39;Pqris&#39;]]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">GapEncoder(n_components=2)</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="#dirty_cat.GapEncoder" title="dirty_cat.GapEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GapEncoder</span></code></a> has found the following two topics:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="go">[&#39;england, london, uk&#39;, &#39;france, paris, pqris&#39;]</span>
</pre></div>
</div>
<p>It got it right, reccuring topics are “London” and “England” on the
one side and “Paris” and “France” on the other.</p>
<p>As this is a continuous encoding, we can look at the level of
activation of each topic for each category:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 0.05202843, 10.54797156],</span>
<span class="go">      [ 0.05000118,  4.54999882],</span>
<span class="go">      [12.04734788,  0.05265212],</span>
<span class="go">      [ 0.05263068, 16.54736932],</span>
<span class="go">      [ 6.04999624,  0.05000376],</span>
<span class="go">      [19.546716  ,  0.053284  ],</span>
<span class="go">      [ 6.04999623,  0.05000376],</span>
<span class="go">      [ 0.05002016,  4.54997983]])</span>
</pre></div>
</div>
<p>The higher the value, the bigger the correspondance with the topic.</p>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>rho_: float</strong></dt><dd><p>Effective update rate for the W matrix</p>
</dd>
<dt><strong>fitted_models_: list of GapEncoderColumn</strong></dt><dd><p>Column-wise fitted GapEncoders</p>
</dd>
<dt><strong>column_names_: list of str</strong></dt><dd><p>Column names of the data the Gap was fitted on</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.fit" title="dirty_cat.GapEncoder.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X[, y])</p></td>
<td><p>Fit the instance on batches of X.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.fit_transform" title="dirty_cat.GapEncoder.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(X[, y])</p></td>
<td><p>Fit to data, then transform it.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.get_feature_names" title="dirty_cat.GapEncoder.get_feature_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names</span></code></a>([input_features, ...])</p></td>
<td><p>Ensures compatibility with sklearn &lt; 1.0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.get_feature_names_out" title="dirty_cat.GapEncoder.get_feature_names_out"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names_out</span></code></a>([col_names, n_labels])</p></td>
<td><p>Returns the labels that best summarize the learned components/topics.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.get_params" title="dirty_cat.GapEncoder.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.partial_fit" title="dirty_cat.GapEncoder.partial_fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_fit</span></code></a>(X[, y])</p></td>
<td><p>Partial fit of the GapEncoder on X.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.score" title="dirty_cat.GapEncoder.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(X)</p></td>
<td><p>Returns the sum over the columns of X of the Kullback-Leibler divergence between the n-grams counts matrix V of X, and its non-negative factorization HW.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.set_output" title="dirty_cat.GapEncoder.set_output"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_output</span></code></a>(*[, transform])</p></td>
<td><p>Set output container.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.set_params" title="dirty_cat.GapEncoder.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dirty_cat.GapEncoder.transform" title="dirty_cat.GapEncoder.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(X)</p></td>
<td><p>Return the encoded vectors (activations) H of input strings in X.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/_gap_encoder.py#L763"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the instance on batches of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape (n_samples, n_features)</span></dt><dd><p>The string data to fit the model on.</p>
</dd>
<dt><strong>y</strong><span class="classifier">None</span></dt><dd><p>Unused, only here for compatibility.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#dirty_cat.GapEncoder" title="dirty_cat.GapEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GapEncoder</span></code></a></dt><dd><p>Fitted <a class="reference internal" href="#dirty_cat.GapEncoder" title="dirty_cat.GapEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">GapEncoder</span></code></a> instance (self).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">fit_params</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/../../miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/base.py#L831"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to <cite>X</cite> and <cite>y</cite> with optional parameters <cite>fit_params</cite>
and returns a transformed version of <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>Input samples.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None</span></dt><dd><p>Target values (None for unsupervised transformations).</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional fit parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">ndarray array of shape (n_samples, n_features_new)</span></dt><dd><p>Transformed array.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.get_feature_names">
<span class="sig-name descname"><span class="pre">get_feature_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/_gap_encoder.py#L912"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Ensures compatibility with sklearn &lt; 1.0.
Use <cite>get_feature_names_out</cite> instead.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.get_feature_names_out">
<span class="sig-name descname"><span class="pre">get_feature_names_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">col_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/_gap_encoder.py#L865"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.get_feature_names_out" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the labels that best summarize the learned components/topics.
For each topic, labels with the highest activations are selected.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>col_names</strong><span class="classifier">typing.Optional[typing.Union[typing.Literal[“auto”], typing.List[str]]], default=None  # noqa</span></dt><dd><p>The column names to be added as prefixes before the labels.
If col_names == None, no prefixes are used.
If col_names == ‘auto’, column names are automatically defined:</p>
<blockquote>
<div><ul class="simple">
<li><p>if the input data was a dataframe, its column names are used,</p></li>
<li><p>otherwise, ‘col1’, …, ‘colN’ are used as prefixes.</p></li>
</ul>
</div></blockquote>
<p>Prefixes can be manually set by passing a list for col_names.</p>
</dd>
<dt><strong>n_labels</strong><span class="classifier">int, default=3</span></dt><dd><p>The number of labels used to describe each topic.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>topic_labels</strong><span class="classifier">list of strings</span></dt><dd><p>The labels that best describe each topic.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/../../miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/base.py#L153"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.partial_fit">
<span class="sig-name descname"><span class="pre">partial_fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/_gap_encoder.py#L830"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Partial fit of the GapEncoder on X.
To be used in an online learning procedure where batches of data are
coming one by one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape (n_samples, n_features)</span></dt><dd><p>The string data to fit the model on.</p>
</dd>
<dt><strong>y</strong><span class="classifier">None</span></dt><dd><p>Unused, only here for compatibility.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>GapEncoder</dt><dd><p>Fitted GapEncoder instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/_gap_encoder.py#L929"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the sum over the columns of X of the Kullback-Leibler
divergence between the n-grams counts matrix V of X, and its
non-negative factorization HW.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like (str), shape (n_samples, n_features)</span></dt><dd><p>The data to encode.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float.</dt><dd><p>The Kullback-Leibler divergence.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.set_output">
<span class="sig-name descname"><span class="pre">set_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/../../miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/_set_output.py#L210"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.set_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Set output container.</p>
<p>See <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py" title="(in scikit-learn v1.2)"><span>Introducing the set_output API</span></a>
for an example on how to use the API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>transform</strong><span class="classifier">{“default”, “pandas”}, default=None</span></dt><dd><p>Configure output of <cite>transform</cite> and <cite>fit_transform</cite>.</p>
<ul class="simple">
<li><p><cite>“default”</cite>: Default output format of a transformer</p></li>
<li><p><cite>“pandas”</cite>: DataFrame output</p></li>
<li><p><cite>None</cite>: Transform configuration is unchanged</p></li>
</ul>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/../../miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/base.py#L177"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dirty_cat.GapEncoder.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dirty-cat/dirty-cat/blob/3babb5d/dirty_cat/_gap_encoder.py#L799"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dirty_cat.GapEncoder.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the encoded vectors (activations) H of input strings in X.
Given the learnt topics W, the activations H are tuned to fit V = HW.
When X has several columns, they are encoded separately and
then concatenated.</p>
<p>Remark: calling transform multiple times in a row on the same
input X can give slightly different encodings. This is expected
due to a caching mechanism to speed things up.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape (n_samples, n_features)</span></dt><dd><p>The string data to encode.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>H</strong><span class="classifier">2-d array, shape (n_samples, n_topics * n_features)</span></dt><dd><p>Transformed input.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-dirty-cat-gapencoder">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">dirty_cat.GapEncoder</span></code><a class="headerlink" href="#examples-using-dirty-cat-gapencoder" title="Permalink to this heading">¶</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Including strings that represent categories often calls for much data preparation. In particula..."><img alt="Dirty categories: machine learning with non normalized strings" src="../_images/sphx_glr_01_dirty_categories_thumb.png" />
<p><a class="reference internal" href="../auto_examples/01_dirty_categories.html#sphx-glr-auto-examples-01-dirty-categories-py"><span class="std std-ref">Dirty categories: machine learning with non normalized strings</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dirty categories: machine learning with non normalized strings</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="What are dirty categorical variables and how can a good encoding help with statistical learning..."><img alt="Investigating and interpreting dirty categories" src="../_images/sphx_glr_02_investigating_dirty_categories_thumb.png" />
<p><a class="reference internal" href="../auto_examples/02_investigating_dirty_categories.html#sphx-glr-auto-examples-02-investigating-dirty-categories-py"><span class="std std-ref">Investigating and interpreting dirty categories</span></a></p>
  <div class="sphx-glr-thumbnail-title">Investigating and interpreting dirty categories</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We discuss in this notebook how to efficiently apply the SimilarityEncoder to larger datasets: ..."><img alt="Scalability considerations for similarity encoding" src="../_images/sphx_glr_04_dimension_reduction_and_performance_thumb.png" />
<p><a class="reference internal" href="../auto_examples/04_dimension_reduction_and_performance.html#sphx-glr-auto-examples-04-dimension-reduction-and-performance-py"><span class="std std-ref">Scalability considerations for similarity encoding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scalability considerations for similarity encoding</div>
</div></div><div class="clearer"></div></section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2018-2023, the dirty_cat developers.
      
      |
      <a href="../_sources/generated/dirty_cat.GapEncoder.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>