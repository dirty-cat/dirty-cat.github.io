
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/04_dimension_reduction_and_performance.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_04_dimension_reduction_and_performance.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_04_dimension_reduction_and_performance.py:


Scalability considerations for similarity encoding
==================================================

We discuss in this notebook how to efficiently apply the SimilarityEncoder
to larger datasets: reducing the number of reference categories to `prototypes`,
either chosen as the most frequent categories, or with kmeans clustering.


.. note::
    The |Gap| naturally does data reduction and comes with online estimation.
    As a result, is it more scalable than the |SE|,
    and should be preferred in large-scale settings.


 .. |SE| replace:: :class:`~dirty_cat.SimilarityEncoder`

 .. |Gap| replace:: :class:`~dirty_cat.GapEncoder`

 .. |ColumnTransformer| replace:: :class:`~sklearn.compose.ColumnTransformer`

 .. |OHE| replace:: :class:`~sklearn.preprocessing.OneHotEncoder`

.. GENERATED FROM PYTHON SOURCE LINES 26-31

A tool to report memory usage and run time
------------------------------------------

For this example, we build a small tool that reports memory
usage and compute time of a function:

.. GENERATED FROM PYTHON SOURCE LINES 31-55

.. code-block:: default

    from time import perf_counter
    import functools
    import tracemalloc


    def resource_used(func):
        """
        Decorator for performance analysis.
        """

        @functools.wraps(func)
        def wrapped_func(*args, **kwargs):
            t0 = perf_counter()  # Launch a time
            tracemalloc.start()
            out = func(*args, **kwargs)
            size, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()
            peak /= 1024**2  # Convert to megabytes
            print(f"Run time: {perf_counter() - t0:.2f}s | Memory used: {peak:.2f}MB. ")
            return out

        return wrapped_func









.. GENERATED FROM PYTHON SOURCE LINES 56-60

Data Importing and preprocessing
--------------------------------

First, let's fetch the dataset we'll use further down:

.. GENERATED FROM PYTHON SOURCE LINES 60-68

.. code-block:: default

    import pandas as pd
    from dirty_cat.datasets import fetch_open_payments

    open_payments = fetch_open_payments()
    X = open_payments.X

    open_payments.description





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    'Payments given by healthcare manufacturing companies to medical doctors or hospitals'



.. GENERATED FROM PYTHON SOURCE LINES 69-70

We'll perform some cleaning:

.. GENERATED FROM PYTHON SOURCE LINES 70-82

.. code-block:: default

    from functools import reduce

    # Remove the missing lines in X
    na_mask: pd.DataFrame = X.isna()
    X = X.dropna(axis=0).reset_index(drop=True)

    y = open_payments.y
    # Combine boolean masks
    na_mask = na_mask.any(axis=1)
    # Drop the lines in y that contained missing values in X
    y = y[~na_mask].reset_index(drop=True)








.. GENERATED FROM PYTHON SOURCE LINES 83-84

We'll write down which columns are clean and which are dirty:

.. GENERATED FROM PYTHON SOURCE LINES 84-94

.. code-block:: default

    clean_columns = [
        "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name",
        "Dispute_Status_for_Publication",
        "Physician_Specialty",
    ]
    dirty_columns = [
        "Name_of_Associated_Covered_Device_or_Medical_Supply1",
        "Name_of_Associated_Covered_Drug_or_Biological1",
    ]








.. GENERATED FROM PYTHON SOURCE LINES 95-98

We will use |SE| on the two dirty columns defined above.
One difficulty is that they have many entries, and because of that, as we'll
see, the |SE| will take a while.

.. GENERATED FROM PYTHON SOURCE LINES 98-100

.. code-block:: default

    X[dirty_columns].value_counts()[:20]





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Name_of_Associated_Covered_Device_or_Medical_Supply1  Name_of_Associated_Covered_Drug_or_Biological1
    Sprix                                                 Sprix                                             95
    PriMatrix                                             PriMatrix                                         61
    Radiesse                                              Xeomin                                            53
    Injectafer                                            Injectafer                                        52
    SurgiMend                                             SurgiMend                                         50
    Biosurgicals                                          Evicel                                            44
    Meters                                                Invokana                                          44
    Belotero                                              Xeomin                                            40
    Essure                                                Mirena                                            39
    SIR-Spheres microspheres                              SIR-Spheres microspheres                          37
    HFCWO                                                 HFCWO                                             33
    BETAMETHASONE SOD PHOS                                BETAMETHASONE SOD PHOS                            32
    MIST Therapy                                          MIST Therapy                                      29
    One Touch Ping                                        Invokana                                          27
    Equinoxe                                              Equinoxe                                          26
    Air-Seal                                              Air-Seal                                          23
    Clarix                                                Neox                                              23
    Optetrak                                              Optetrak                                          18
    OsteoSelect DBM Putty                                 Osteosponge                                       17
    Novation                                              Novation                                          15
    dtype: int64



.. GENERATED FROM PYTHON SOURCE LINES 101-103

.. code-block:: default

    X[dirty_columns].nunique()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Name_of_Associated_Covered_Device_or_Medical_Supply1    223
    Name_of_Associated_Covered_Drug_or_Biological1          210
    dtype: int64



.. GENERATED FROM PYTHON SOURCE LINES 104-109

|SE| with default options
-------------------------

Let us build our vectorizer, using a |ColumnTransformer| to combine
a |OHE| and a |SE|.

.. GENERATED FROM PYTHON SOURCE LINES 109-132

.. code-block:: default

    from sklearn.preprocessing import OneHotEncoder
    from sklearn.compose import ColumnTransformer
    from dirty_cat import SimilarityEncoder

    clean_col_transformer = [
        (
            "one_hot",
            OneHotEncoder(sparse=False, handle_unknown="ignore"),
            clean_columns,
        ),
    ]

    column_trans = ColumnTransformer(
        transformers=clean_col_transformer
        + [("sim_enc", SimilarityEncoder(), dirty_columns)],
        remainder="drop",
    )

    t0 = perf_counter()
    X_enc = column_trans.fit_transform(X)
    t1 = perf_counter()
    print(f"Time to vectorize: {t1 - t0:.3f}s")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Time to vectorize: 0.260s




.. GENERATED FROM PYTHON SOURCE LINES 133-134

Let's now run a cross-validation:

.. GENERATED FROM PYTHON SOURCE LINES 134-144

.. code-block:: default

    from sklearn import pipeline, model_selection
    from sklearn.linear_model import LogisticRegression

    # We specify max_iter to avoid convergence warnings
    log_reg = LogisticRegression(max_iter=10000)

    model = pipeline.make_pipeline(column_trans, log_reg)
    results = resource_used(model_selection.cross_validate)(model, X, y)
    print(f"Cross-validation score: {results['test_score']}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Run time: 1.81s | Memory used: 12.18MB. 
    Cross-validation score: [0.98513011 0.98884758 0.96641791 0.98134328 0.98880597]




.. GENERATED FROM PYTHON SOURCE LINES 145-146

We store the results for later:

.. GENERATED FROM PYTHON SOURCE LINES 146-151

.. code-block:: default

    scores = dict()
    scores["Default options"] = results["test_score"]
    times = dict()
    times["Default options"] = results["fit_time"]








.. GENERATED FROM PYTHON SOURCE LINES 152-159

Most frequent strategy to define prototypes
-------------------------------------------

The ``most_frequent`` strategy selects the `n` most frequent
values in a dirty categorical variable to reduce the dimensionality of the
problem and thus speed things up.
Here, we arbitrarily choose 100 as the number of prototypes we want to use.

.. GENERATED FROM PYTHON SOURCE LINES 159-172

.. code-block:: default


    column_trans = ColumnTransformer(
        transformers=clean_col_transformer
        + [
            (
                "sim_enc",
                SimilarityEncoder(categories="most_frequent", n_prototypes=100),
                dirty_columns,
            )
        ],
        remainder="drop",
    )








.. GENERATED FROM PYTHON SOURCE LINES 173-174

Check that the prediction is still as good:

.. GENERATED FROM PYTHON SOURCE LINES 174-178

.. code-block:: default

    model = pipeline.make_pipeline(column_trans, log_reg)
    results = resource_used(model_selection.cross_validate)(model, X, y)
    print(f"Cross-validation score: {results['test_score']}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Run time: 1.57s | Memory used: 9.08MB. 
    Cross-validation score: [0.98513011 0.99256506 0.97014925 0.98507463 0.98880597]




.. GENERATED FROM PYTHON SOURCE LINES 179-180

Store results for later:

.. GENERATED FROM PYTHON SOURCE LINES 180-183

.. code-block:: default

    scores["Most frequent"] = results["test_score"]
    times["Most frequent"] = results["fit_time"]








.. GENERATED FROM PYTHON SOURCE LINES 184-191

KMeans strategy to define prototypes
------------------------------------

The ``k-means`` strategy is also a dimensionality reduction technique.
The |SE| can apply a K-means and nearest neighbors
algorithm to find the prototypes. Once again, the number of prototypes
we chose here is arbitrary.

.. GENERATED FROM PYTHON SOURCE LINES 191-204

.. code-block:: default


    column_trans = ColumnTransformer(
        transformers=clean_col_transformer
        + [
            (
                "sim_enc",
                SimilarityEncoder(categories="k-means", n_prototypes=100),
                dirty_columns,
            )
        ],
        remainder="drop",
    )








.. GENERATED FROM PYTHON SOURCE LINES 205-206

Check that the prediction is still as good:

.. GENERATED FROM PYTHON SOURCE LINES 206-210

.. code-block:: default

    model = pipeline.make_pipeline(column_trans, log_reg)
    results = resource_used(model_selection.cross_validate)(model, X, y)
    print("Cross-validation score: %s" % results["test_score"])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Run time: 4.49s | Memory used: 8.55MB. 
    Cross-validation score: [0.98884758 0.99256506 0.97014925 0.98507463 0.98880597]




.. GENERATED FROM PYTHON SOURCE LINES 211-212

Store results for later:

.. GENERATED FROM PYTHON SOURCE LINES 212-215

.. code-block:: default

    scores["KMeans"] = results["test_score"]
    times["KMeans"] = results["fit_time"]








.. GENERATED FROM PYTHON SOURCE LINES 216-218

Summary
-------

.. GENERATED FROM PYTHON SOURCE LINES 218-230

.. code-block:: default

    import seaborn
    import matplotlib.pyplot as plt

    _, (ax1, ax2) = plt.subplots(nrows=2, figsize=(4, 3))
    seaborn.boxplot(data=pd.DataFrame(scores), orient="h", ax=ax1)
    ax1.set_xlabel("Prediction accuracy", size=16)
    [t.set(size=16) for t in ax1.get_yticklabels()]

    seaborn.boxplot(data=pd.DataFrame(times), orient="h", ax=ax2)
    ax2.set_xlabel("Computation time", size=16)
    [t.set(size=16) for t in ax2.get_yticklabels()]
    plt.tight_layout()



.. image-sg:: /auto_examples/images/sphx_glr_04_dimension_reduction_and_performance_001.png
   :alt: 04 dimension reduction and performance
   :srcset: /auto_examples/images/sphx_glr_04_dimension_reduction_and_performance_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  14.952 seconds)


.. _sphx_glr_download_auto_examples_04_dimension_reduction_and_performance.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/dirty-cat/dirty-cat.github.io/main?filepath=dev/auto_examples/04_dimension_reduction_and_performance.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 04_dimension_reduction_and_performance.py <04_dimension_reduction_and_performance.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 04_dimension_reduction_and_performance.ipynb <04_dimension_reduction_and_performance.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
