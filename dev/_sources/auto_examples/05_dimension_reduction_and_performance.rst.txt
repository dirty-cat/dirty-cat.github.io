
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/05_dimension_reduction_and_performance.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_05_dimension_reduction_and_performance.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_05_dimension_reduction_and_performance.py:


Scalability considerations for similarity encoding
===================================================

Here we discuss how to apply efficiently SimilarityEncoder to larger
datasets: reducing the number of reference categories to "prototypes",
either chosen as the most frequent categories, or with kmeans clustering.

Note that the :class:`GapEncoder` naturally does data reduction and comes
with online estimation. As a result is it more scalable than the
SimilarityEncoder, and should be preferred in large-scale settings.

.. GENERATED FROM PYTHON SOURCE LINES 14-19

.. code-block:: default

    # Avoid the warning in scikit-learn's LogisticRegression for the change
    # in the solver
    import warnings
    warnings.simplefilter(action='ignore', category=FutureWarning)








.. GENERATED FROM PYTHON SOURCE LINES 20-25

A tool to report memory usage and run time
------------------------------------------

For this example, we build a small tool that reports memory
usage and compute time of a function

.. GENERATED FROM PYTHON SOURCE LINES 25-49

.. code-block:: default

    from time import time
    import functools
    import tracemalloc


    def resource_used(func):
        """ Decorator that return a function that prints its usage
        """

        @functools.wraps(func)
        def wrapped_func(*args, **kwargs):
            t0 = time()
            tracemalloc.start()
            out = func(*args, **kwargs)
            size, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()
            peak /= (1024 ** 2)  # Convert to megabytes
            print("Run time: %.1is    Memory used: %iMb"
                  % (time() - t0, peak))
            return out

        return wrapped_func









.. GENERATED FROM PYTHON SOURCE LINES 50-54

Data Importing and preprocessing
--------------------------------

We first get the dataset:

.. GENERATED FROM PYTHON SOURCE LINES 54-86

.. code-block:: default

    import pandas as pd
    from dirty_cat.datasets import fetch_open_payments

    open_payments = fetch_open_payments()
    print(open_payments.description)

    df = open_payments.X

    na_mask: pd.DataFrame = df.isna()
    df = df.dropna(axis=0)
    df = df.reset_index()

    from functools import reduce

    y = open_payments.y
    # Combine boolean masks
    na_mask = reduce(lambda acc, col: acc | na_mask[col],
                     na_mask.columns, na_mask[na_mask.columns[0]])
    # Drop the lines that contained missing values in X
    y = y[~na_mask]
    y.reset_index()

    clean_columns = [
        'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name',
        'Dispute_Status_for_Publication',
        'Physician_Specialty',
    ]
    dirty_columns = [
        'Name_of_Associated_Covered_Device_or_Medical_Supply1',
        'Name_of_Associated_Covered_Drug_or_Biological1',
    ]





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/project/dirty_cat/datasets/fetching.py:113: UserWarning: Could not find the dataset 42738 locally. Downloading it from OpenML; this might take a while... If it is interrupted, some files might be invalid/incomplete: if on the following run, the fetching raises errors, you can try fixing this issue by deleting the directory PosixPath('/home/circleci/project/dirty_cat/datasets/data').
      warnings.warn(
    Payments given by healthcare manufacturing companies to medical doctors or hospitals




.. GENERATED FROM PYTHON SOURCE LINES 87-89

We will use SimilarityEncoder on the the two dirty columns defined above.
One difficulty is that they have many different entries.

.. GENERATED FROM PYTHON SOURCE LINES 89-91

.. code-block:: default

    print(df[dirty_columns].nunique())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Name_of_Associated_Covered_Device_or_Medical_Supply1    223
    Name_of_Associated_Covered_Drug_or_Biological1          210
    dtype: int64




.. GENERATED FROM PYTHON SOURCE LINES 92-94

.. code-block:: default

    print(df[dirty_columns].value_counts()[:20])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Name_of_Associated_Covered_Device_or_Medical_Supply1  Name_of_Associated_Covered_Drug_or_Biological1
    Sprix                                                 Sprix                                             95
    PriMatrix                                             PriMatrix                                         61
    Radiesse                                              Xeomin                                            53
    Injectafer                                            Injectafer                                        52
    SurgiMend                                             SurgiMend                                         50
    Biosurgicals                                          Evicel                                            44
    Meters                                                Invokana                                          44
    Belotero                                              Xeomin                                            40
    Essure                                                Mirena                                            39
    SIR-Spheres microspheres                              SIR-Spheres microspheres                          37
    HFCWO                                                 HFCWO                                             33
    BETAMETHASONE SOD PHOS                                BETAMETHASONE SOD PHOS                            32
    MIST Therapy                                          MIST Therapy                                      29
    One Touch Ping                                        Invokana                                          27
    Equinoxe                                              Equinoxe                                          26
    Air-Seal                                              Air-Seal                                          23
    Clarix                                                Neox                                              23
    Optetrak                                              Optetrak                                          18
    OsteoSelect DBM Putty                                 Osteosponge                                       17
    Novation                                              Novation                                          15
    dtype: int64




.. GENERATED FROM PYTHON SOURCE LINES 95-96

As we will see, SimilarityEncoder takes a while on such data.

.. GENERATED FROM PYTHON SOURCE LINES 99-104

SimilarityEncoder with default options
--------------------------------------

Let us build our vectorizer, using a ColumnTransformer to combine
one-hot encoding and similarity encoding

.. GENERATED FROM PYTHON SOURCE LINES 104-123

.. code-block:: default

    from sklearn.preprocessing import OneHotEncoder
    from sklearn.compose import ColumnTransformer
    from dirty_cat import SimilarityEncoder

    sim_enc = SimilarityEncoder(similarity='ngram')

    transformers = [
        ('one_hot', OneHotEncoder(sparse=False, handle_unknown='ignore'), clean_columns),
    ]

    column_trans = ColumnTransformer(
        transformers=transformers + [('sim_enc', sim_enc, dirty_columns)],
        remainder='drop')

    t0 = time()
    X = column_trans.fit_transform(df)
    t1 = time()
    print('Time to vectorize: %s' % (t1 - t0))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Time to vectorize: 0.8078858852386475




.. GENERATED FROM PYTHON SOURCE LINES 124-125

We can run a cross-validation

.. GENERATED FROM PYTHON SOURCE LINES 125-134

.. code-block:: default

    from sklearn import linear_model, pipeline, model_selection

    # We specify max_iter to avoid convergence warnings
    log_reg = linear_model.LogisticRegression(max_iter=10000)

    model = pipeline.make_pipeline(column_trans, log_reg)
    results = resource_used(model_selection.cross_validate)(model, df, y)
    print("Cross-validation score: %s" % results['test_score'])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Run time: 6s    Memory used: 12Mb
    Cross-validation score: [0.98513011 0.98884758 0.96641791 0.98134328 0.98880597]




.. GENERATED FROM PYTHON SOURCE LINES 135-136

Store results for later

.. GENERATED FROM PYTHON SOURCE LINES 136-141

.. code-block:: default

    scores = dict()
    scores['Default options'] = results['test_score']
    times = dict()
    times['Default options'] = results['fit_time']








.. GENERATED FROM PYTHON SOURCE LINES 142-148

Most frequent strategy to define prototypes
-------------------------------------------

The most frequent strategy selects the n most frequent values in a dirty
categorical variable to reduce the dimensionality of the problem and thus
speed things up. We select manually the number of prototypes we want to use.

.. GENERATED FROM PYTHON SOURCE LINES 148-155

.. code-block:: default

    sim_enc = SimilarityEncoder(similarity='ngram', categories='most_frequent',
                                n_prototypes=100)

    column_trans = ColumnTransformer(
        transformers=transformers + [('sim_enc', sim_enc, dirty_columns)],
        remainder='drop')








.. GENERATED FROM PYTHON SOURCE LINES 156-157

Check now that prediction is still as good

.. GENERATED FROM PYTHON SOURCE LINES 157-161

.. code-block:: default

    model = pipeline.make_pipeline(column_trans, log_reg)
    results = resource_used(model_selection.cross_validate)(model, df, y)
    print("Cross-validation score: %s" % results['test_score'])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Run time: 5s    Memory used: 9Mb
    Cross-validation score: [0.98513011 0.99256506 0.97014925 0.98507463 0.98880597]




.. GENERATED FROM PYTHON SOURCE LINES 162-163

Store results for later

.. GENERATED FROM PYTHON SOURCE LINES 163-166

.. code-block:: default

    scores['Most frequent'] = results['test_score']
    times['Most frequent'] = results['fit_time']








.. GENERATED FROM PYTHON SOURCE LINES 167-173

KMeans strategy to define prototypes
------------------------------------

K-means strategy is also a dimensionality reduction technique.
SimilarityEncoder can apply a K-means and nearest neighbors algorithm
to find the prototypes. The number of prototypes is set manually.

.. GENERATED FROM PYTHON SOURCE LINES 173-180

.. code-block:: default

    sim_enc = SimilarityEncoder(similarity='ngram', categories='k-means',
                                n_prototypes=100)

    column_trans = ColumnTransformer(
        transformers=transformers + [('sim_enc', sim_enc, dirty_columns)],
        remainder='drop')








.. GENERATED FROM PYTHON SOURCE LINES 181-182

Check now that prediction is still as good

.. GENERATED FROM PYTHON SOURCE LINES 182-186

.. code-block:: default

    model = pipeline.make_pipeline(column_trans, log_reg)
    results = resource_used(model_selection.cross_validate)(model, df, y)
    print("Cross-validation score: %s" % results['test_score'])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Run time: 19s    Memory used: 8Mb
    Cross-validation score: [0.98884758 0.99256506 0.97014925 0.98507463 0.98880597]




.. GENERATED FROM PYTHON SOURCE LINES 187-188

Store results for later

.. GENERATED FROM PYTHON SOURCE LINES 188-191

.. code-block:: default

    scores['KMeans'] = results['test_score']
    times['KMeans'] = results['fit_time']








.. GENERATED FROM PYTHON SOURCE LINES 192-194

Plot a summary figure
---------------------

.. GENERATED FROM PYTHON SOURCE LINES 194-206

.. code-block:: default

    import seaborn
    import matplotlib.pyplot as plt

    _, (ax1, ax2) = plt.subplots(nrows=2, figsize=(4, 3))
    seaborn.boxplot(data=pd.DataFrame(scores), orient='h', ax=ax1)
    ax1.set_xlabel('Prediction accuracy', size=16)
    [t.set(size=16) for t in ax1.get_yticklabels()]

    seaborn.boxplot(data=pd.DataFrame(times), orient='h', ax=ax2)
    ax2.set_xlabel('Computation time', size=16)
    [t.set(size=16) for t in ax2.get_yticklabels()]
    plt.tight_layout()



.. image-sg:: /auto_examples/images/sphx_glr_05_dimension_reduction_and_performance_001.png
   :alt: 05 dimension reduction and performance
   :srcset: /auto_examples/images/sphx_glr_05_dimension_reduction_and_performance_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1582: UserWarning: Trying to register the cmap 'rocket' which already exists.
      mpl_cm.register_cmap(_name, _cmap)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1583: UserWarning: Trying to register the cmap 'rocket_r' which already exists.
      mpl_cm.register_cmap(_name + "_r", _cmap_r)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1582: UserWarning: Trying to register the cmap 'mako' which already exists.
      mpl_cm.register_cmap(_name, _cmap)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1583: UserWarning: Trying to register the cmap 'mako_r' which already exists.
      mpl_cm.register_cmap(_name + "_r", _cmap_r)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1582: UserWarning: Trying to register the cmap 'icefire' which already exists.
      mpl_cm.register_cmap(_name, _cmap)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1583: UserWarning: Trying to register the cmap 'icefire_r' which already exists.
      mpl_cm.register_cmap(_name + "_r", _cmap_r)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1582: UserWarning: Trying to register the cmap 'vlag' which already exists.
      mpl_cm.register_cmap(_name, _cmap)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1583: UserWarning: Trying to register the cmap 'vlag_r' which already exists.
      mpl_cm.register_cmap(_name + "_r", _cmap_r)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1582: UserWarning: Trying to register the cmap 'flare' which already exists.
      mpl_cm.register_cmap(_name, _cmap)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1583: UserWarning: Trying to register the cmap 'flare_r' which already exists.
      mpl_cm.register_cmap(_name + "_r", _cmap_r)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1582: UserWarning: Trying to register the cmap 'crest' which already exists.
      mpl_cm.register_cmap(_name, _cmap)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/seaborn/cm.py:1583: UserWarning: Trying to register the cmap 'crest_r' which already exists.
      mpl_cm.register_cmap(_name + "_r", _cmap_r)





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  41.149 seconds)


.. _sphx_glr_download_auto_examples_05_dimension_reduction_and_performance.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/dirty-cat/dirty-cat.github.io/master?filepath=dev/auto_examples/05_dimension_reduction_and_performance.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: 05_dimension_reduction_and_performance.py <05_dimension_reduction_and_performance.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: 05_dimension_reduction_and_performance.ipynb <05_dimension_reduction_and_performance.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
