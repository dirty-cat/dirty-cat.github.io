
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/01_dirty_categories.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_01_dirty_categories.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_01_dirty_categories.py:


==============================================================
Dirty categories: machine learning with non normalized strings
==============================================================

Including strings that represent categories often calls for much data
preparation. In particular categories may appear with many morphological
variants, when they have been manually input, or assembled from diverse
sources.

Including such a column in a learning pipeline as a standard categorical
column leads to categories with very high cardinalities and can loose
information on which categories are similar.
Here we look at a dataset on wages [#]_ where the column *Employee
Position Title* contains dirty categories.

.. [#] https://catalog.data.gov/dataset/employee-salaries-2016

We investigate encodings to include this dirty column in the machine learning
workflow, and predict the *current annual salary*, using gradient boosted
trees.


 .. |SV| replace::
     :class:`~dirty_cat.SuperVectorizer`

 .. |Pipeline| replace::
     :class:`~sklearn.pipeline.Pipeline`

 .. |OneHotEncoder| replace::
     :class:`~sklearn.preprocessing.OneHotEncoder`

 .. |ColumnTransformer| replace::
     :class:`~sklearn.compose.ColumnTransformer`

 .. |RandomForestRegressor| replace::
     :class:`~sklearn.ensemble.RandomForestRegressor`

 .. |Gap| replace::
     :class:`~dirty_cat.GapEncoder`

 .. |SE| replace:: :class:`~dirty_cat.SimilarityEncoder`

 .. |permutation importances| replace::
     :func:`~sklearn.inspection.permutation_importance`

.. GENERATED FROM PYTHON SOURCE LINES 49-56

The data
========

Data Importing and preprocessing
--------------------------------

We first get the dataset:

.. GENERATED FROM PYTHON SOURCE LINES 57-60

.. code-block:: default

    from dirty_cat.datasets import fetch_employee_salaries
    employee_salaries = fetch_employee_salaries()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/project/dirty_cat/datasets/fetching.py:113: UserWarning: Could not find the dataset 42125 locally. Downloading it from OpenML; this might take a while... If it is interrupted, some files might be invalid/incomplete: if on the following run, the fetching raises errors, you can try fixing this issue by deleting the directory PosixPath('/home/circleci/project/dirty_cat/datasets/data').
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 61-62

Let's get X, the dataset:

.. GENERATED FROM PYTHON SOURCE LINES 62-65

.. code-block:: default

    X = employee_salaries.X
    X






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>gender</th>
          <th>department</th>
          <th>department_name</th>
          <th>division</th>
          <th>assignment_category</th>
          <th>employee_position_title</th>
          <th>underfilled_job_title</th>
          <th>date_first_hired</th>
          <th>year_first_hired</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>F</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>MSB Information Mgmt and Tech Division Records...</td>
          <td>Fulltime-Regular</td>
          <td>Office Services Coordinator</td>
          <td>NaN</td>
          <td>09/22/1986</td>
          <td>1986</td>
        </tr>
        <tr>
          <th>1</th>
          <td>M</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>ISB Major Crimes Division Fugitive Section</td>
          <td>Fulltime-Regular</td>
          <td>Master Police Officer</td>
          <td>NaN</td>
          <td>09/12/1988</td>
          <td>1988</td>
        </tr>
        <tr>
          <th>2</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Adult Protective and Case Management Services</td>
          <td>Fulltime-Regular</td>
          <td>Social Worker IV</td>
          <td>NaN</td>
          <td>11/19/1989</td>
          <td>1989</td>
        </tr>
        <tr>
          <th>3</th>
          <td>M</td>
          <td>COR</td>
          <td>Correction and Rehabilitation</td>
          <td>PRRS Facility and Security</td>
          <td>Fulltime-Regular</td>
          <td>Resident Supervisor II</td>
          <td>NaN</td>
          <td>05/05/2014</td>
          <td>2014</td>
        </tr>
        <tr>
          <th>4</th>
          <td>M</td>
          <td>HCA</td>
          <td>Department of Housing and Community Affairs</td>
          <td>Affordable Housing Programs</td>
          <td>Fulltime-Regular</td>
          <td>Planning Specialist III</td>
          <td>NaN</td>
          <td>03/05/2007</td>
          <td>2007</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>9223</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>School Based Health Centers</td>
          <td>Fulltime-Regular</td>
          <td>Community Health Nurse II</td>
          <td>NaN</td>
          <td>11/03/2015</td>
          <td>2015</td>
        </tr>
        <tr>
          <th>9224</th>
          <td>F</td>
          <td>FRS</td>
          <td>Fire and Rescue Services</td>
          <td>Human Resources Division</td>
          <td>Fulltime-Regular</td>
          <td>Fire/Rescue Division Chief</td>
          <td>NaN</td>
          <td>11/28/1988</td>
          <td>1988</td>
        </tr>
        <tr>
          <th>9225</th>
          <td>M</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Child and Adolescent Mental Health Clinic Serv...</td>
          <td>Parttime-Regular</td>
          <td>Medical Doctor IV - Psychiatrist</td>
          <td>NaN</td>
          <td>04/30/2001</td>
          <td>2001</td>
        </tr>
        <tr>
          <th>9226</th>
          <td>M</td>
          <td>CCL</td>
          <td>County Council</td>
          <td>Council Central Staff</td>
          <td>Fulltime-Regular</td>
          <td>Manager II</td>
          <td>NaN</td>
          <td>09/05/2006</td>
          <td>2006</td>
        </tr>
        <tr>
          <th>9227</th>
          <td>M</td>
          <td>DLC</td>
          <td>Department of Liquor Control</td>
          <td>Licensure, Regulation and Education</td>
          <td>Fulltime-Regular</td>
          <td>Alcohol/Tobacco Enforcement Specialist II</td>
          <td>NaN</td>
          <td>01/30/2012</td>
          <td>2012</td>
        </tr>
      </tbody>
    </table>
    <p>9228 rows × 9 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 66-67

and y, our target column

.. GENERATED FROM PYTHON SOURCE LINES 67-70

.. code-block:: default

    y = employee_salaries.y
    y.name





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    'current_annual_salary'



.. GENERATED FROM PYTHON SOURCE LINES 71-72

Now, let's carry out some basic preprocessing:

.. GENERATED FROM PYTHON SOURCE LINES 72-81

.. code-block:: default

    import pandas as pd
    X['date_first_hired'] = pd.to_datetime(X['date_first_hired'])
    X['year_first_hired'] = X['date_first_hired'].apply(lambda x: x.year)
    # Get mask of rows with missing values in gender
    mask = X.isna()['gender']
    # And remove the lines accordingly
    X.dropna(subset=['gender'], inplace=True)
    y = y[~mask]








.. GENERATED FROM PYTHON SOURCE LINES 82-90

Assembling a machine-learning pipeline that encodes the data
============================================================

The learning pipeline
---------------------

To build a learning pipeline, we need to assemble encoders for each
column, and apply a supervised learning model on top.

.. GENERATED FROM PYTHON SOURCE LINES 93-98

The categorical encoders
........................

An encoder is needed to turn a categorical column into a numerical
representation

.. GENERATED FROM PYTHON SOURCE LINES 98-102

.. code-block:: default

    from sklearn.preprocessing import OneHotEncoder

    one_hot = OneHotEncoder(handle_unknown='ignore', sparse=False)








.. GENERATED FROM PYTHON SOURCE LINES 103-106

We assemble these to apply them to the relevant columns.
The ColumnTransformer is created by specifying a set of transformers
alongside with the column names on which each must be applied

.. GENERATED FROM PYTHON SOURCE LINES 106-116

.. code-block:: default


    from sklearn.compose import make_column_transformer
    encoder = make_column_transformer(
        (one_hot, ['gender', 'department_name', 'assignment_category']),
        ('passthrough', ['year_first_hired']),
        # Last but not least, our dirty column
        (one_hot, ['employee_position_title']),
        remainder='drop',
       )








.. GENERATED FROM PYTHON SOURCE LINES 117-123

Pipelining an encoder with a learner
....................................

We will use a HistGradientBoostingRegressor, which is a good predictor
for data with heterogeneous columns
(we need to require the experimental feature for scikit-learn 0.24)

.. GENERATED FROM PYTHON SOURCE LINES 123-131

.. code-block:: default

    from sklearn.experimental import enable_hist_gradient_boosting
    # now you can import the HGBR from ensemble
    from sklearn.ensemble import HistGradientBoostingRegressor

    # We then create a pipeline chaining our encoders to a learner
    from sklearn.pipeline import make_pipeline
    pipeline = make_pipeline(encoder, HistGradientBoostingRegressor())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 132-133

The pipeline can be readily applied to the dataframe for prediction

.. GENERATED FROM PYTHON SOURCE LINES 133-135

.. code-block:: default

    pipeline.fit(X, y)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Pipeline(steps=[('columntransformer',
                     ColumnTransformer(transformers=[('onehotencoder-1',
                                                      OneHotEncoder(handle_unknown='ignore',
                                                                    sparse=False),
                                                      ['gender', 'department_name',
                                                       'assignment_category']),
                                                     ('passthrough', 'passthrough',
                                                      ['year_first_hired']),
                                                     ('onehotencoder-2',
                                                      OneHotEncoder(handle_unknown='ignore',
                                                                    sparse=False),
                                                      ['employee_position_title'])])),
                    ('histgradientboostingregressor',
                     HistGradientBoostingRegressor())])



.. GENERATED FROM PYTHON SOURCE LINES 136-141

Dirty-category encoding
-----------------------

The one-hot encoder is actually not well suited to the 'Employee
Position Title' column, as this columns contains 400 different entries:

.. GENERATED FROM PYTHON SOURCE LINES 141-144

.. code-block:: default

    import numpy as np
    np.unique(y)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    array([  9196.  ,  11147.24,  13244.5 , ..., 233003.  , 239566.  ,
           303091.  ])



.. GENERATED FROM PYTHON SOURCE LINES 145-147

We will now experiment with encoders specially made for handling
dirty columns

.. GENERATED FROM PYTHON SOURCE LINES 147-158

.. code-block:: default

    from dirty_cat import SimilarityEncoder, TargetEncoder, MinHashEncoder,\
        GapEncoder

    encoders = {
        'one-hot': one_hot,
        'similarity': SimilarityEncoder(similarity='ngram'),
        'target': TargetEncoder(handle_unknown='ignore'),
        'minhash': MinHashEncoder(n_components=100),
        'gap': GapEncoder(n_components=100),
    }








.. GENERATED FROM PYTHON SOURCE LINES 159-162

We now loop over the different encoding methods,
instantiate a new |Pipeline| each time, fit it
and store the returned cross-validation score:

.. GENERATED FROM PYTHON SOURCE LINES 162-183

.. code-block:: default


    from sklearn.model_selection import cross_val_score

    all_scores = dict()

    for name, method in encoders.items():
        encoder = make_column_transformer(
            (one_hot, ['gender', 'department_name', 'assignment_category']),
            ('passthrough', ['year_first_hired']),
            # Last but not least, our dirty column
            (method, ['employee_position_title']),
            remainder='drop',
        )

        pipeline = make_pipeline(encoder, HistGradientBoostingRegressor())
        scores = cross_val_score(pipeline, X, y)
        print(f'{name} encoding')
        print(f'r2 score:  mean: {np.mean(scores):.3f}; '
              f'std: {np.std(scores):.3f}\n')
        all_scores[name] = scores





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    one-hot encoding
    r2 score:  mean: 0.776; std: 0.028

    similarity encoding
    r2 score:  mean: 0.923; std: 0.014

    target encoding
    r2 score:  mean: 0.842; std: 0.030

    minhash encoding
    r2 score:  mean: 0.919; std: 0.012

    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    gap encoding
    r2 score:  mean: 0.910; std: 0.013





.. GENERATED FROM PYTHON SOURCE LINES 184-188

Plotting the results
....................

Finally, we plot the scores on a boxplot:

.. GENERATED FROM PYTHON SOURCE LINES 188-198

.. code-block:: default


    import seaborn
    import matplotlib.pyplot as plt
    plt.figure(figsize=(4, 3))
    ax = seaborn.boxplot(data=pd.DataFrame(all_scores), orient='h')
    plt.ylabel('Encoding', size=20)
    plt.xlabel('Prediction accuracy     ', size=20)
    plt.yticks(size=20)
    plt.tight_layout()




.. image-sg:: /auto_examples/images/sphx_glr_01_dirty_categories_001.png
   :alt: 01 dirty categories
   :srcset: /auto_examples/images/sphx_glr_01_dirty_categories_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 199-210

The clear trend is that encoders grasping the similarities in the category
(similarity, minhash, and gap) perform better than those discarding it.

SimilarityEncoder is the best performer, but it is less scalable on big
data than MinHashEncoder and GapEncoder. The most scalable encoder is
the MinHashEncoder. GapEncoder, on the other hand, has the benefit that
it provides interpretable features
(see :ref:`sphx_glr_auto_examples_03_feature_interpretation_gap_encoder.py`)

|


.. GENERATED FROM PYTHON SOURCE LINES 212-219

A simpler way: automatic vectorization
======================================

The code to assemble the column transformer is a bit tedious. We will
now explore a simpler, automated, way of encoding the data.

Let's start again from the raw data:

.. GENERATED FROM PYTHON SOURCE LINES 219-223

.. code-block:: default

    employee_salaries = fetch_employee_salaries()
    X = employee_salaries.X
    y = employee_salaries.y








.. GENERATED FROM PYTHON SOURCE LINES 224-225

We'll drop a column we don't want

.. GENERATED FROM PYTHON SOURCE LINES 225-227

.. code-block:: default

    X = X.drop(['date_first_hired'], axis=1)  # Redundant with "year_first_hired"








.. GENERATED FROM PYTHON SOURCE LINES 228-229

We still have a complex and heterogeneous dataframe:

.. GENERATED FROM PYTHON SOURCE LINES 229-231

.. code-block:: default

    X






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>gender</th>
          <th>department</th>
          <th>department_name</th>
          <th>division</th>
          <th>assignment_category</th>
          <th>employee_position_title</th>
          <th>underfilled_job_title</th>
          <th>year_first_hired</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>F</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>MSB Information Mgmt and Tech Division Records...</td>
          <td>Fulltime-Regular</td>
          <td>Office Services Coordinator</td>
          <td>NaN</td>
          <td>1986</td>
        </tr>
        <tr>
          <th>1</th>
          <td>M</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>ISB Major Crimes Division Fugitive Section</td>
          <td>Fulltime-Regular</td>
          <td>Master Police Officer</td>
          <td>NaN</td>
          <td>1988</td>
        </tr>
        <tr>
          <th>2</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Adult Protective and Case Management Services</td>
          <td>Fulltime-Regular</td>
          <td>Social Worker IV</td>
          <td>NaN</td>
          <td>1989</td>
        </tr>
        <tr>
          <th>3</th>
          <td>M</td>
          <td>COR</td>
          <td>Correction and Rehabilitation</td>
          <td>PRRS Facility and Security</td>
          <td>Fulltime-Regular</td>
          <td>Resident Supervisor II</td>
          <td>NaN</td>
          <td>2014</td>
        </tr>
        <tr>
          <th>4</th>
          <td>M</td>
          <td>HCA</td>
          <td>Department of Housing and Community Affairs</td>
          <td>Affordable Housing Programs</td>
          <td>Fulltime-Regular</td>
          <td>Planning Specialist III</td>
          <td>NaN</td>
          <td>2007</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>9223</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>School Based Health Centers</td>
          <td>Fulltime-Regular</td>
          <td>Community Health Nurse II</td>
          <td>NaN</td>
          <td>2015</td>
        </tr>
        <tr>
          <th>9224</th>
          <td>F</td>
          <td>FRS</td>
          <td>Fire and Rescue Services</td>
          <td>Human Resources Division</td>
          <td>Fulltime-Regular</td>
          <td>Fire/Rescue Division Chief</td>
          <td>NaN</td>
          <td>1988</td>
        </tr>
        <tr>
          <th>9225</th>
          <td>M</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Child and Adolescent Mental Health Clinic Serv...</td>
          <td>Parttime-Regular</td>
          <td>Medical Doctor IV - Psychiatrist</td>
          <td>NaN</td>
          <td>2001</td>
        </tr>
        <tr>
          <th>9226</th>
          <td>M</td>
          <td>CCL</td>
          <td>County Council</td>
          <td>Council Central Staff</td>
          <td>Fulltime-Regular</td>
          <td>Manager II</td>
          <td>NaN</td>
          <td>2006</td>
        </tr>
        <tr>
          <th>9227</th>
          <td>M</td>
          <td>DLC</td>
          <td>Department of Liquor Control</td>
          <td>Licensure, Regulation and Education</td>
          <td>Fulltime-Regular</td>
          <td>Alcohol/Tobacco Enforcement Specialist II</td>
          <td>NaN</td>
          <td>2012</td>
        </tr>
      </tbody>
    </table>
    <p>9228 rows × 8 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 232-234

The |SV| can to turn this dataframe into a form suited for
machine learning.

.. GENERATED FROM PYTHON SOURCE LINES 236-242

Using the SuperVectorizer in a supervised-learning pipeline
-----------------------------------------------------------

Assembling the |SV| in a |Pipeline| with a powerful learner,
such as gradient boosted trees, gives **a machine-learning method that
can be readily applied to the dataframe**.

.. GENERATED FROM PYTHON SOURCE LINES 242-253

.. code-block:: default


    # The SuperVectorizer requires at least dirty_cat 0.2.0. 
    #

    from dirty_cat import SuperVectorizer

    pipeline = make_pipeline(
        SuperVectorizer(auto_cast=True),
        HistGradientBoostingRegressor()
    )








.. GENERATED FROM PYTHON SOURCE LINES 254-255

Let's perform a cross-validation to see how well this model predicts

.. GENERATED FROM PYTHON SOURCE LINES 255-263

.. code-block:: default


    from sklearn.model_selection import cross_val_score
    scores = cross_val_score(pipeline, X, y, scoring='r2')

    print(f'scores={scores}')
    print(f'mean={np.mean(scores)}')
    print(f'std={np.std(scores)}')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    scores=[0.90417768 0.89584176 0.92587016 0.92900167 0.92111851]
    mean=0.9152019540242042
    std=0.012927491938453202




.. GENERATED FROM PYTHON SOURCE LINES 264-267

The prediction performed here is pretty much as good as above
but the code here is much simpler as it does not involve specifying
columns manually.

.. GENERATED FROM PYTHON SOURCE LINES 269-274

Analyzing the features created
------------------------------

Let us perform the same workflow, but without the |Pipeline|, so we can
analyze its mechanisms along the way.

.. GENERATED FROM PYTHON SOURCE LINES 274-276

.. code-block:: default

    sup_vec = SuperVectorizer(auto_cast=True)








.. GENERATED FROM PYTHON SOURCE LINES 277-278

We split the data between train and test, and transform them:

.. GENERATED FROM PYTHON SOURCE LINES 278-286

.. code-block:: default

    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.15, random_state=42
    )

    X_train_enc = sup_vec.fit_transform(X_train, y_train)
    X_test_enc = sup_vec.transform(X_test)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)
    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)




.. GENERATED FROM PYTHON SOURCE LINES 287-288

The encoded data, X_train_enc and X_test_enc are numerical arrays:

.. GENERATED FROM PYTHON SOURCE LINES 288-290

.. code-block:: default

    X_train_enc





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    array([[0.0, 1.0, 0.0, ..., 0.05695295856959702, 0.05661868158717038,
            2007],
           [1.0, 0.0, 0.0, ..., 0.050000000000000044, 0.050000000000000044,
            2005],
           [1.0, 0.0, 0.0, ..., 0.050000000000000044, 0.050000000000000044,
            2009],
           ...,
           [1.0, 0.0, 0.0, ..., 0.050000000000000044, 0.050000000000000044,
            1990],
           [0.0, 1.0, 0.0, ..., 0.050000000000000044, 0.050000000000000044,
            2012],
           [1.0, 0.0, 0.0, ..., 0.050000000000000044, 0.050000000000000044,
            2014]], dtype=object)



.. GENERATED FROM PYTHON SOURCE LINES 291-292

They have more columns than the original dataframe, but not much more:

.. GENERATED FROM PYTHON SOURCE LINES 292-294

.. code-block:: default

    (X_train.shape, X_train_enc.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    ((7843, 8), (7843, 170))



.. GENERATED FROM PYTHON SOURCE LINES 295-300

Inspecting the features created
...............................

The |SV| assigns a transformer for each column. We can inspect this
choice:

.. GENERATED FROM PYTHON SOURCE LINES 300-302

.. code-block:: default

    sup_vec.transformers_





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    [('low_card_cat', OneHotEncoder(), ['gender', 'department', 'department_name', 'assignment_category']), ('high_card_cat', GapEncoder(n_components=30), ['division', 'employee_position_title', 'underfilled_job_title']), ('remainder', 'passthrough', [7])]



.. GENERATED FROM PYTHON SOURCE LINES 303-316

This is what is being passed to the |ColumnTransformer| under the hood.
If you're familiar with how the later works, it should be very intuitive.
We can notice it classified the columns "gender" and "assignment_category"
as low cardinality string variables.
A |OneHotEncoder| will be applied to these columns.

The vectorizer actually makes the difference between string variables
(data type ``object`` and ``string``) and categorical variables
(data type ``category``).

Next, we can have a look at the encoded feature names.

Before encoding:

.. GENERATED FROM PYTHON SOURCE LINES 316-318

.. code-block:: default

    X.columns.to_list()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    ['gender', 'department', 'department_name', 'division', 'assignment_category', 'employee_position_title', 'underfilled_job_title', 'year_first_hired']



.. GENERATED FROM PYTHON SOURCE LINES 319-320

After encoding (we only plot the first 8 feature names):

.. GENERATED FROM PYTHON SOURCE LINES 320-323

.. code-block:: default

    feature_names = sup_vec.get_feature_names()
    feature_names[:8]





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/miniconda/envs/testenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
      warnings.warn(msg, category=FutureWarning)

    ['gender_F', 'gender_M', 'gender_nan', 'department_BOA', 'department_BOE', 'department_CAT', 'department_CCL', 'department_CEC']



.. GENERATED FROM PYTHON SOURCE LINES 324-330

As we can see, it gave us interpretable columns.
This is because we used |Gap| on the column "division",
which was classified as a high cardinality string variable.
(default values, see |SV|'s docstring).

In total, we have reasonable number of encoded columns.

.. GENERATED FROM PYTHON SOURCE LINES 330-333

.. code-block:: default

    len(feature_names)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    170



.. GENERATED FROM PYTHON SOURCE LINES 334-346

Feature importances in the statistical model
--------------------------------------------

In this section, we will train a regressor, and plot the feature importances

.. topic:: Note:

   To minimize compute time, use the feature importances computed by the
   |RandomForestRegressor|, but you should prefer |permutation importances|
   instead (which are less subject to biases)

First, let's train the |RandomForestRegressor|,

.. GENERATED FROM PYTHON SOURCE LINES 346-350

.. code-block:: default

    from sklearn.ensemble import RandomForestRegressor
    regressor = RandomForestRegressor()
    regressor.fit(X_train_enc, y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    RandomForestRegressor()



.. GENERATED FROM PYTHON SOURCE LINES 351-352

Retrieving the feature importances

.. GENERATED FROM PYTHON SOURCE LINES 352-364

.. code-block:: default

    importances = regressor.feature_importances_
    std = np.std(
        [
            tree.feature_importances_
            for tree in regressor.estimators_
        ],
        axis=0
    )
    indices = np.argsort(importances)
    # Sort from least to most
    indices = list(reversed(indices))








.. GENERATED FROM PYTHON SOURCE LINES 365-366

Plotting the results:

.. GENERATED FROM PYTHON SOURCE LINES 366-378

.. code-block:: default


    import matplotlib.pyplot as plt
    plt.figure(figsize=(12, 9))
    plt.title("Feature importances")
    n = 20
    n_indices = indices[:n]
    labels = np.array(feature_names)[n_indices]
    plt.barh(range(n), importances[n_indices], color="b", yerr=std[n_indices])
    plt.yticks(range(n), labels, size=15)
    plt.tight_layout(pad=1)
    plt.show()




.. image-sg:: /auto_examples/images/sphx_glr_01_dirty_categories_002.png
   :alt: Feature importances
   :srcset: /auto_examples/images/sphx_glr_01_dirty_categories_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 379-390

We can deduce from this data that the three factors that define the
most the salary are: being hired for a long time, being a manager, and
having a permanent, full-time job :)


.. topic:: The SuperVectorizer automates preprocessing

  As this notebook demonstrates, many preprocessing steps can be
  automated by the |SV|, and the resulting pipeline can still be
  inspected, even with non-normalized entries.



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 6 minutes  20.524 seconds)


.. _sphx_glr_download_auto_examples_01_dirty_categories.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/dirty-cat/dirty-cat.github.io/master?filepath=dev/auto_examples/01_dirty_categories.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: 01_dirty_categories.py <01_dirty_categories.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: 01_dirty_categories.ipynb <01_dirty_categories.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
