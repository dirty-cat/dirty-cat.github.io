
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>dirty_cat.gap_encoder &#8212; dirty_cat 0.0.7 documentation</title>
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../index.html">
    <img class="logo" src="../../_static/dirty_cat.svg" alt="Logo"/>
    
    <h1 class="logo logo-name">dirty_cat</h1>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=dirty-cat&repo=dirty_cat&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<hr />
<ul>
    <li class="toctree-l1"><a href="../../index.html#using-dirty-cat">Usage</a></li>
    <li class="toctree-l1"><a href="../../index.html#api-documentation">API</a></li>
    <li class="toctree-l1"><a href="../../index.html#about">About</a></li>
</ul><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for dirty_cat.gap_encoder</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Online Gamma-Poisson factorization of string arrays.</span>
<span class="sd">The principle is as follows:</span>
<span class="sd">    1. Given an input string array X, we build its bag-of-n-grams</span>
<span class="sd">       representation V (n_samples, vocab_size).</span>
<span class="sd">    2. Instead of using the n-grams counts as encodings, we look for low-</span>
<span class="sd">       dimensional representations by modeling n-grams counts as linear</span>
<span class="sd">       combinations of topics V = HW, with W (n_topics, vocab_size) the topics</span>
<span class="sd">       and H (n_samples, n_topics) the associated activations.</span>
<span class="sd">    3. Assuming that n-grams counts follow a Poisson law, we fit H and W to</span>
<span class="sd">       maximize the likelihood of the data, with a Gamma prior for the</span>
<span class="sd">       activations H to induce sparsity.</span>
<span class="sd">    4. In practice, this is equivalent to a non-negative matrix factorization</span>
<span class="sd">       with the Kullback-Leibler divergence as loss, and a Gamma prior on H.</span>
<span class="sd">       We thus optimize H and W with the multiplicative update method.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="kn">import</span> <span class="n">LooseVersion</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">sklearn_version</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span><span class="p">,</span> <span class="n">gen_batches</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="kn">import</span> <span class="n">row_norms</span><span class="p">,</span> <span class="n">safe_sparse_dot</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><span class="p">,</span> <span class="n">HashingVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;0.22&#39;</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.cluster.k_means_</span> <span class="kn">import</span> <span class="n">_k_init</span>
<span class="k">elif</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;0.24&#39;</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.cluster._kmeans</span> <span class="kn">import</span> <span class="n">_k_init</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">kmeans_plusplus</span>

<span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;0.22&#39;</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.decomposition.nmf</span> <span class="kn">import</span> <span class="n">_beta_divergence</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.decomposition._nmf</span> <span class="kn">import</span> <span class="n">_beta_divergence</span>


<div class="viewcode-block" id="GapEncoder"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder">[docs]</a><span class="k">class</span> <span class="nc">GapEncoder</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This encoder can be understood as a continuous encoding on a set of latent</span>
<span class="sd">    categories estimated from the data. The latent categories are built by</span>
<span class="sd">    capturing combinations of substrings that frequently co-occur.</span>
<span class="sd">    </span>
<span class="sd">    The GapEncoder supports online learning on batches of data for</span>
<span class="sd">    scalability through the partial_fit method.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    n_components : int, default=10</span>
<span class="sd">        Number of latent categories used to model string data.</span>

<span class="sd">    batch_size : int, default=128</span>
<span class="sd">        Number of samples per batch.</span>

<span class="sd">    gamma_shape_prior : float, default=1.1</span>
<span class="sd">        Shape parameter for the Gamma prior distribution.</span>

<span class="sd">    gamma_scale_prior : float, default=1.0</span>
<span class="sd">        Scale parameter for the Gamma prior distribution.</span>

<span class="sd">    rho : float, default=0.95</span>
<span class="sd">        Weight parameter for the update of the W matrix.</span>
<span class="sd">    </span>
<span class="sd">    rescale_rho : bool, default=False</span>
<span class="sd">        If true, use rho ** (batch_size / len(X)) instead of rho to obtain an</span>
<span class="sd">        update rate per iteration that is independent of the batch size.</span>

<span class="sd">    hashing : bool, default=False</span>
<span class="sd">        If true, HashingVectorizer is used instead of CountVectorizer.</span>
<span class="sd">        It has the advantage of being very low memory scalable to large</span>
<span class="sd">        datasets as there is no need to store a vocabulary dictionary in</span>
<span class="sd">        memory.</span>

<span class="sd">    hashing_n_features : int, default=2**12</span>
<span class="sd">        Number of features for the HashingVectorizer. Only relevant if</span>
<span class="sd">        hashing=True.</span>

<span class="sd">    init : str, default=&#39;k-means++&#39;</span>
<span class="sd">        Initialization method of the W matrix.</span>
<span class="sd">        Options: {&#39;k-means++&#39;, &#39;random&#39;, &#39;k-means&#39;}.</span>
<span class="sd">        If init=&#39;k-means++&#39;, we use the init method of sklearn.cluster.KMeans.</span>
<span class="sd">        If init=&#39;random&#39;, topics are initialized with a Gamma distribution.</span>
<span class="sd">        If init=&#39;k-means&#39;, topics are initialized with a KMeans on the n-grams</span>
<span class="sd">        counts. This usually makes convergence faster but is a bit slower.</span>

<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Tolerance for the convergence of the matrix W.</span>

<span class="sd">    min_iter : int, default=2</span>
<span class="sd">        Minimum number of iterations on the input data.</span>

<span class="sd">    max_iter : int, default=5</span>
<span class="sd">        Maximum number of iterations on the input data.</span>

<span class="sd">    ngram_range : tuple, default=(2, 4)</span>
<span class="sd">        The range of ngram length that will be used to build the</span>
<span class="sd">        bag-of-n-grams representation of the input data.</span>

<span class="sd">    analyzer : str, default=&#39;char&#39;.</span>
<span class="sd">        Analyzer parameter for the CountVectorizer/HashingVectorizer.</span>
<span class="sd">        Options: {‘word’, ‘char’, ‘char_wb’}, describing whether the matrix V</span>
<span class="sd">        to factorize should be made of word counts or character n-gram counts.</span>
<span class="sd">        Option ‘char_wb’ creates character n-grams only from text inside word</span>
<span class="sd">        boundaries; n-grams at the edges of words are padded with space.</span>

<span class="sd">    add_words : bool, default=False</span>
<span class="sd">        If true, add the words counts to the bag-of-n-grams representation</span>
<span class="sd">        of the input data.</span>

<span class="sd">    random_state : int or None, default=None</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>

<span class="sd">    rescale_W : bool, default=True</span>
<span class="sd">        If true, the weight matrix W is rescaled at each iteration</span>
<span class="sd">        to have an l1 norm equal to 1 for each row.</span>
<span class="sd">    </span>
<span class="sd">    max_iter_e_step : int, default=20</span>
<span class="sd">        Maximum number of iterations to adjust the activations h at each step.</span>


<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    For a detailed description of the method, see</span>
<span class="sd">    `Encoding high-cardinality string categorical variables</span>
<span class="sd">    &lt;https://hal.inria.fr/hal-02171256v4&gt;`_ by Cerda, Varoquaux (2019).</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GapEncoder.__init__"><a class="viewcode-back" href="../../generated/dirty_cat.GapEncoder.html#dirty_cat.GapEncoder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span>
                 <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">rho</span><span class="o">=.</span><span class="mi">95</span><span class="p">,</span> <span class="n">rescale_rho</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">hashing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">hashing_n_features</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">12</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span>
                 <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">min_iter</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
                 <span class="n">analyzer</span><span class="o">=</span><span class="s1">&#39;char&#39;</span><span class="p">,</span> <span class="n">add_words</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">rescale_W</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_iter_e_step</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ngram_range</span> <span class="o">=</span> <span class="n">ngram_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span> <span class="o">=</span> <span class="n">gamma_shape_prior</span>  <span class="c1"># &#39;a&#39; parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span> <span class="o">=</span> <span class="n">gamma_scale_prior</span>  <span class="c1"># &#39;b&#39; parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">=</span> <span class="n">rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_rho</span> <span class="o">=</span> <span class="n">rescale_rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hashing</span> <span class="o">=</span> <span class="n">hashing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hashing_n_features</span> <span class="o">=</span> <span class="n">hashing_n_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_iter</span> <span class="o">=</span> <span class="n">min_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">analyzer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span> <span class="o">=</span> <span class="n">add_words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span> <span class="o">=</span> <span class="n">rescale_W</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span> <span class="o">=</span> <span class="n">max_iter_e_step</span></div>

    <span class="k">def</span> <span class="nf">_init_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the bag-of-n-grams representation V of X and initialize</span>
<span class="sd">        the topics W.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Init n-grams counts vectorizer</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hashing</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span>
                 <span class="n">analyzer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ngram_range</span><span class="p">,</span>
                 <span class="n">n_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hashing_n_features</span><span class="p">,</span>
                 <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alternate_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span> <span class="c1"># Init a word counts vectorizer if needed</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span>
                     <span class="n">analyzer</span><span class="o">=</span><span class="s1">&#39;word&#39;</span><span class="p">,</span>
                     <span class="n">n_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hashing_n_features</span><span class="p">,</span>
                     <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alternate_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span>
                 <span class="n">analyzer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ngram_range</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c1"># Init H_dict_ with empty dict to train from scratch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># Build the n-grams counts matrix unq_V on unique elements of X</span>
        <span class="n">unq_X</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">unq_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span> <span class="c1"># Add word counts to unq_V</span>
            <span class="n">unq_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
            <span class="n">unq_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">unq_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hashing</span><span class="p">:</span> <span class="c1"># Build n-grams/word vocabulary</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()))</span>

        <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span> <span class="o">=</span> <span class="n">unq_V</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># Init the topics W given the n-grams counts V</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_w</span><span class="p">(</span><span class="n">unq_V</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span> <span class="n">X</span><span class="p">)</span>
        <span class="c1"># Init the activations unq_H of each unique input string</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="n">_rescale_h</span><span class="p">(</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">unq_X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)))</span>
        <span class="c1"># Update self.H_dict_ with unique input strings and their activations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_rho</span><span class="p">:</span>
            <span class="c1"># Make update rate per iteration independant of the batch_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_V</span><span class="p">,</span> <span class="n">lookup</span>

    <span class="k">def</span> <span class="nf">_get_H</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the bag-of-n-grams representation of X.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">H_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">h_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">H_out</span><span class="p">):</span>
            <span class="n">h_out</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">H_out</span>

    <span class="k">def</span> <span class="nf">_init_w</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the topics W.</span>
<span class="sd">        If self.init=&#39;k-means++&#39;, we use the init method of</span>
<span class="sd">        sklearn.cluster.KMeans.</span>
<span class="sd">        If self.init=&#39;random&#39;, topics are initialized with a Gamma</span>
<span class="sd">        distribution.</span>
<span class="sd">        If self.init=&#39;k-means&#39;, topics are initialized with a KMeans on the</span>
<span class="sd">        n-grams counts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;k-means++&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;0.24&#39;</span><span class="p">):</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">_k_init</span><span class="p">(</span>
                    <span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span>
                    <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">+</span> <span class="o">.</span><span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">W</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">kmeans_plusplus</span><span class="p">(</span>
                    <span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span>
                    <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                    <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">+</span> <span class="o">.</span><span class="mi">1</span> <span class="c1"># To avoid restricting topics to few n-grams only</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">==</span> <span class="s1">&#39;k-means&#39;</span><span class="p">:</span>
            <span class="n">prototypes</span> <span class="o">=</span> <span class="n">get_kmeans_prototypes</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">prototypes</span><span class="p">)</span><span class="o">.</span><span class="n">A</span> <span class="o">+</span> <span class="o">.</span><span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="n">W2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">prototypes</span><span class="p">)</span><span class="o">.</span><span class="n">A</span> <span class="o">+</span> <span class="o">.</span><span class="mi">1</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">W</span><span class="p">,</span> <span class="n">W2</span><span class="p">))</span>
            <span class="c1"># if k-means doesn&#39;t find the exact number of prototypes</span>
            <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;0.24&#39;</span><span class="p">):</span>
                    <span class="n">W2</span> <span class="o">=</span> <span class="n">_k_init</span><span class="p">(</span>
                        <span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">-</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                        <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">+</span> <span class="o">.</span><span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">W2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">kmeans_plusplus</span><span class="p">(</span>
                        <span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">-</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="n">x_squared_norms</span><span class="o">=</span><span class="n">row_norms</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                        <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
                    <span class="n">W2</span> <span class="o">=</span> <span class="n">W2</span> <span class="o">+</span> <span class="o">.</span><span class="mi">1</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">W</span><span class="p">,</span> <span class="n">W2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="s1">&#39;Initialization method </span><span class="si">%s</span><span class="s1"> does not exist.&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">/=</span> <span class="n">W</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vocab</span><span class="p">))</span> <span class="o">*</span> <span class="mf">1e-10</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the GapEncoder on batches of X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, ) or (n_samples, 1)</span>
<span class="sd">            The string data to fit the model on.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check input data shape</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;ERROR:</span><span class="se">\</span>
<span class="s2">        shape </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> of input array is not supported.&quot;</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Check if first item has str or np.str_ type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">&quot;ERROR: Input data is not string.&quot;</span>
        <span class="c1"># Make n-grams counts matrix unq_V</span>
        <span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_V</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_vars</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_batch</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">del</span> <span class="n">X</span>
        <span class="c1"># Get activations unq_H</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">n_iter_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="c1"># Loop over batches</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">unq_idx</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_lookup</span><span class="p">(</span>
              <span class="n">lookup</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">n_batch</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                    <span class="n">W_last</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="c1"># Update the activations unq_H</span>
                <span class="n">unq_H</span><span class="p">[</span><span class="n">unq_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span>
                    <span class="n">unq_V</span><span class="p">[</span><span class="n">unq_idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">[</span><span class="n">unq_idx</span><span class="p">],</span>
                    <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span><span class="p">,</span>
                    <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
                    <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
                    <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">)</span>
                <span class="c1"># Update the topics self.W_</span>
                <span class="n">_multiplicative_update_w</span><span class="p">(</span>
                    <span class="n">unq_V</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">n_batch</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># Compute the norm of the update of W in the last batch</span>
                    <span class="n">W_change</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">W_</span> <span class="o">-</span> <span class="n">W_last</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">W_last</span><span class="p">)</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">W_change</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">n_iter_</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_iter</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="k">break</span> <span class="c1"># Stop if the change in W is smaller than the tolerance</span>

        <span class="c1"># Update self.H_dict_ with the learned encoded vectors (activations)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">get_feature_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_labels</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the labels that best summarize the learned components/topics.</span>
<span class="sd">        For each topic, labels with highest activations are selected.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        n_labels : int, default=3</span>
<span class="sd">            The number of labels used to describe each topic.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        </span>
<span class="sd">        topic_labels : list of strings</span>
<span class="sd">            The labels that best describe each topic.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
        <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        <span class="n">vocabulary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">encoding</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">n_components</span> <span class="o">=</span> <span class="n">encoding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">topic_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_components</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)[:</span><span class="n">n_labels</span><span class="p">]]</span>
            <span class="n">topic_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">topic_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">topic_labels</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">topic_labels</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the Kullback-Leibler divergence between the n-grams counts</span>
<span class="sd">        matrix V of X, and its non-negative factorization HW.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like (str), shape (n_samples, )</span>
<span class="sd">            The data to encode.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        kl_divergence : float.</span>
<span class="sd">            The Kullback-Leibler divergence.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Build n-grams/word counts matrix</span>
        <span class="n">unq_X</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">unq_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
            <span class="n">unq_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
            <span class="n">unq_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">unq_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_add_unseen_keys_to_H_dict</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="c1"># Given the learnt topics W, optimize the activations H to fit V = HW</span>
        <span class="k">for</span> <span class="nb">slice</span> <span class="ow">in</span> <span class="n">gen_batches</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">unq_H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                 <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">unq_H</span><span class="p">[</span><span class="nb">slice</span><span class="p">]</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span>
                <span class="n">unq_V</span><span class="p">[</span><span class="nb">slice</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">[</span><span class="nb">slice</span><span class="p">],</span>
                <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span><span class="p">,</span>
                <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
                <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
                <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">)</span>
        <span class="c1"># Compute the KL divergence between V and HW</span>
        <span class="n">kl_divergence</span> <span class="o">=</span> <span class="n">_beta_divergence</span><span class="p">(</span>
            <span class="n">unq_V</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span> <span class="n">unq_H</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span>
            <span class="s1">&#39;kullback-leibler&#39;</span><span class="p">,</span> <span class="n">square_root</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">kl_divergence</span>

    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Partial fit of the GapEncoder on X.</span>
<span class="sd">        To be used in a online learning procedure where batches of data are</span>
<span class="sd">        coming one by one.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, ) or (n_samples, 1)</span>
<span class="sd">            The string data to fit the model on.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Init H_dict_ with empty dict if it&#39;s the first call of partial_fit</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;H_dict_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># Check input data shape</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;ERROR:</span><span class="se">\</span>
<span class="s2">        shape </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> of input array is not supported.&quot;</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Check if first item has str or np.str_ type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">&quot;ERROR: Input data is not string.&quot;</span>
        <span class="c1"># Check if it is not the first batch</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;vocabulary&#39;</span><span class="p">):</span> <span class="c1"># Update unq_X, unq_V with new batch</span>
            <span class="n">unq_X</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">unq_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="n">unq_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
                <span class="n">unq_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">unq_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>

            <span class="n">unseen_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="p">]))</span>
            <span class="n">unseen_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="n">unseen_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">)</span>
                <span class="n">unseen_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unseen_V</span><span class="p">,</span> <span class="n">unseen_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">unseen_V</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">unseen_H</span> <span class="o">=</span> <span class="n">_rescale_h</span><span class="p">(</span>
                    <span class="n">unseen_V</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)))</span>
                <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">,</span> <span class="n">unseen_H</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
                <span class="k">del</span> <span class="n">unseen_H</span>
            <span class="k">del</span> <span class="n">unseen_X</span><span class="p">,</span> <span class="n">unseen_V</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># If it is the first batch, call _init_vars to init unq_X, unq_V</span>
            <span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_V</span><span class="p">,</span> <span class="n">lookup</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_vars</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">unq_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="c1"># Update the activations unq_H</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span>
            <span class="n">unq_V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">,</span>
            <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter_e_step</span><span class="p">,</span>
            <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
            <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
            <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">)</span>
        <span class="c1"># Update the topics self.W_</span>
        <span class="n">_multiplicative_update_w</span><span class="p">(</span>
            <span class="n">unq_V</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span>
            <span class="n">unq_H</span><span class="p">[</span><span class="n">lookup</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho_</span><span class="p">)</span>
        <span class="c1"># Update self.H_dict_ with the learned encoded vectors (activations)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_add_unseen_keys_to_H_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add activations of unseen string categories from X to H_dict.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">unseen_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">unseen_X</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">unseen_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span>
                <span class="n">unseen_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">)</span>
                <span class="n">unseen_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unseen_V</span><span class="p">,</span> <span class="n">unseen_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>

            <span class="n">unseen_H</span> <span class="o">=</span> <span class="n">_rescale_h</span><span class="p">(</span>
                <span class="n">unseen_V</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">unseen_V</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unseen_X</span><span class="p">,</span> <span class="n">unseen_H</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the encoded vectors (activations) H of input strings in X.</span>
<span class="sd">        Given the learnt topics W, the activations H are tuned to fit V = HW.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, ) or (n_samples, 1)</span>
<span class="sd">            The string data to encode.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        H : 2-d array, shape (n_samples, n_topics)</span>
<span class="sd">            Transformed input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check input data shape</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;ERROR:</span><span class="se">\</span>
<span class="s2">        shape </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> of input array is not supported.&quot;</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Check if first item has str or np.str_ type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span> <span class="s2">&quot;ERROR: Input data is not string.&quot;</span>
        <span class="n">unq_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># Build the n-grams counts matrix V for the string data to encode</span>
        <span class="n">unq_V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ngrams_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_words</span><span class="p">:</span> <span class="c1"># Add words counts</span>
            <span class="n">unq_V2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_count_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
            <span class="n">unq_V</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">unq_V</span><span class="p">,</span> <span class="n">unq_V2</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>
        <span class="c1"># Add unseen strings in X to H_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_unseen_keys_to_H_dict</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="n">unq_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">unq_X</span><span class="p">)</span>
        <span class="c1"># Loop over batches</span>
        <span class="k">for</span> <span class="nb">slice</span> <span class="ow">in</span> <span class="n">gen_batches</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">unq_H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                 <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># Given the learnt topics W, optimize H to fit V = HW</span>
            <span class="n">unq_H</span><span class="p">[</span><span class="nb">slice</span><span class="p">]</span> <span class="o">=</span> <span class="n">_multiplicative_update_h</span><span class="p">(</span>
                <span class="n">unq_V</span><span class="p">[</span><span class="nb">slice</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">[</span><span class="nb">slice</span><span class="p">],</span>
                <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                <span class="n">rescale_W</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_W</span><span class="p">,</span>
                <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_shape_prior</span><span class="p">,</span>
                <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_scale_prior</span><span class="p">)</span>
        <span class="c1"># Store and return the encoded vectors of X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_dict_</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unq_X</span><span class="p">,</span> <span class="n">unq_H</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_H</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_rescale_W</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rescale the topics W to have a L1-norm equal to 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">W</span> <span class="o">/=</span> <span class="n">s</span>
    <span class="n">A</span> <span class="o">/=</span> <span class="n">s</span>
    <span class="k">return</span>


<span class="k">def</span> <span class="nf">_multiplicative_update_w</span><span class="p">(</span><span class="n">Vt</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">Ht</span><span class="p">,</span> <span class="n">rescale_W</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multiplicative update step for the topics W.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">A</span> <span class="o">*=</span> <span class="n">rho</span>
    <span class="n">A</span> <span class="o">+=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">Ht</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Vt</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ht</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">B</span> <span class="o">*=</span> <span class="n">rho</span>
    <span class="n">B</span> <span class="o">+=</span> <span class="n">Ht</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">W</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rescale_W</span><span class="p">:</span>
        <span class="n">_rescale_W</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span>


<span class="k">def</span> <span class="nf">_rescale_h</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">H</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rescale the activations H.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-10</span>  <span class="c1"># in case of a document having length=0</span>
    <span class="n">H</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">A</span><span class="p">)</span>
    <span class="n">H</span> <span class="o">/=</span> <span class="n">H</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">H</span>


<span class="k">def</span> <span class="nf">_multiplicative_update_h</span><span class="p">(</span><span class="n">Vt</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">Ht</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                             <span class="n">rescale_W</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">gamma_shape_prior</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">gamma_scale_prior</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multiplicative update step for the activations H.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">rescale_W</span><span class="p">:</span>
        <span class="n">WT1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">gamma_scale_prior</span>
        <span class="n">W_WT1</span> <span class="o">=</span> <span class="n">W</span> <span class="o">/</span> <span class="n">WT1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">WT1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">gamma_scale_prior</span>
        <span class="n">W_WT1</span> <span class="o">=</span> <span class="n">W</span> <span class="o">/</span> <span class="n">WT1</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">const</span> <span class="o">=</span> <span class="p">(</span><span class="n">gamma_shape_prior</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">WT1</span>
    <span class="n">squared_epsilon</span> <span class="o">=</span> <span class="n">epsilon</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">for</span> <span class="n">vt</span><span class="p">,</span> <span class="n">ht</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Vt</span><span class="p">,</span> <span class="n">Ht</span><span class="p">):</span>
        <span class="n">vt_</span> <span class="o">=</span> <span class="n">vt</span><span class="o">.</span><span class="n">data</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">vt</span><span class="o">.</span><span class="n">indices</span>
        <span class="n">W_WT1_</span> <span class="o">=</span> <span class="n">W_WT1</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
        <span class="n">W_</span> <span class="o">=</span> <span class="n">W</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span>
        <span class="n">squared_norm</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">n_iter_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">squared_norm</span> <span class="o">&lt;=</span> <span class="n">squared_epsilon</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">aux</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W_WT1_</span><span class="p">,</span> <span class="n">vt_</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ht</span><span class="p">,</span> <span class="n">W_</span><span class="p">))</span>
            <span class="n">ht_out</span> <span class="o">=</span> <span class="n">ht</span> <span class="o">*</span> <span class="n">aux</span> <span class="o">+</span> <span class="n">const</span>
            <span class="n">squared_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                <span class="n">ht_out</span> <span class="o">-</span> <span class="n">ht</span><span class="p">,</span> <span class="n">ht_out</span> <span class="o">-</span> <span class="n">ht</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ht</span><span class="p">,</span> <span class="n">ht</span><span class="p">)</span>
            <span class="n">ht</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">ht_out</span>
    <span class="k">return</span> <span class="n">Ht</span>


<span class="k">def</span> <span class="nf">batch_lookup</span><span class="p">(</span><span class="n">lookup</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Make batches of the lookup array. &quot;&quot;&quot;</span>
    <span class="n">len_iter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lookup</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">len_iter</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">lookup</span><span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="n">len_iter</span><span class="p">))]</span>
        <span class="n">unq_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">unq_indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_kmeans_prototypes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_prototypes</span><span class="p">,</span> <span class="n">hashing_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes prototypes based on:</span>
<span class="sd">      - dimensionality reduction (via hashing n-grams)</span>
<span class="sd">      - k-means clustering</span>
<span class="sd">      - nearest neighbor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span><span class="n">analyzer</span><span class="o">=</span><span class="s1">&#39;char&#39;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">alternate_sign</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                   <span class="n">ngram_range</span><span class="o">=</span><span class="n">ngram_range</span><span class="p">,</span>
                                   <span class="n">n_features</span><span class="o">=</span><span class="n">hashing_dim</span><span class="p">)</span>
    <span class="n">projected</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse</span><span class="p">:</span>
        <span class="n">projected</span> <span class="o">=</span> <span class="n">projected</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_prototypes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">projected</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
    <span class="n">neighbors</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">()</span>
    <span class="n">neighbors</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">projected</span><span class="p">)</span>
    <span class="n">indexes_prototypes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">neighbors</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">centers</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">indexes_prototypes</span><span class="p">])</span>
</pre></div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2018, dirty_cat developers.
      
    </div>

    

    
  </body>
</html>